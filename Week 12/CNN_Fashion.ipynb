{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Device Name: NVIDIA GeForce GTX 1660\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Memastikan penggunaan GPU jika tersedia\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Device Name:\", torch.cuda.get_device_name(0))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, kernel_size, pooling_type):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        if pooling_type == 'max':\n",
    "            self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        elif pooling_type == 'avg':\n",
    "            self.pooling = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pooling(torch.relu(self.conv1(x)))\n",
    "        x = self.pooling(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_model(model, optimizer, scheduler, criterion, num_epochs=5):\n",
    "    early_stop_patience = 10\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Validation Loss\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(test_loader)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early Stopping\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=5, Optimizer=SGD\n",
      "Epoch 1/5, Loss: 1.2596\n",
      "Epoch 2/5, Loss: 0.5803\n",
      "Epoch 3/5, Loss: 0.5091\n",
      "Epoch 4/5, Loss: 0.4607\n",
      "Epoch 5/5, Loss: 0.4328\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=5, Optimizer=RMSProp\n",
      "Epoch 1/5, Loss: 0.4510\n",
      "Epoch 2/5, Loss: 0.2789\n",
      "Epoch 3/5, Loss: 0.2317\n",
      "Epoch 4/5, Loss: 0.2012\n",
      "Epoch 5/5, Loss: 0.1755\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=5, Optimizer=Adam\n",
      "Epoch 1/5, Loss: 0.4890\n",
      "Epoch 2/5, Loss: 0.3157\n",
      "Epoch 3/5, Loss: 0.2694\n",
      "Epoch 4/5, Loss: 0.2380\n",
      "Epoch 5/5, Loss: 0.2146\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=50, Optimizer=SGD\n",
      "Epoch 1/50, Loss: 1.2517\n",
      "Epoch 2/50, Loss: 0.6117\n",
      "Epoch 3/50, Loss: 0.5353\n",
      "Epoch 4/50, Loss: 0.4889\n",
      "Epoch 5/50, Loss: 0.4523\n",
      "Epoch 6/50, Loss: 0.4249\n",
      "Epoch 7/50, Loss: 0.4040\n",
      "Epoch 8/50, Loss: 0.3895\n",
      "Epoch 9/50, Loss: 0.3737\n",
      "Epoch 10/50, Loss: 0.3601\n",
      "Epoch 11/50, Loss: 0.3523\n",
      "Epoch 12/50, Loss: 0.3415\n",
      "Epoch 13/50, Loss: 0.3346\n",
      "Epoch 14/50, Loss: 0.3254\n",
      "Epoch 15/50, Loss: 0.3189\n",
      "Epoch 16/50, Loss: 0.3123\n",
      "Epoch 17/50, Loss: 0.3063\n",
      "Epoch 18/50, Loss: 0.3009\n",
      "Epoch 19/50, Loss: 0.2938\n",
      "Epoch 20/50, Loss: 0.2906\n",
      "Epoch 21/50, Loss: 0.2840\n",
      "Epoch 22/50, Loss: 0.2804\n",
      "Epoch 23/50, Loss: 0.2754\n",
      "Epoch 24/50, Loss: 0.2715\n",
      "Epoch 25/50, Loss: 0.2669\n",
      "Epoch 26/50, Loss: 0.2624\n",
      "Epoch 27/50, Loss: 0.2596\n",
      "Epoch 28/50, Loss: 0.2566\n",
      "Epoch 29/50, Loss: 0.2522\n",
      "Epoch 30/50, Loss: 0.2485\n",
      "Epoch 31/50, Loss: 0.2458\n",
      "Epoch 32/50, Loss: 0.2420\n",
      "Epoch 33/50, Loss: 0.2380\n",
      "Epoch 34/50, Loss: 0.2365\n",
      "Epoch 35/50, Loss: 0.2328\n",
      "Epoch 36/50, Loss: 0.2313\n",
      "Epoch 37/50, Loss: 0.2271\n",
      "Epoch 38/50, Loss: 0.2253\n",
      "Epoch 39/50, Loss: 0.2230\n",
      "Epoch 40/50, Loss: 0.2200\n",
      "Epoch 41/50, Loss: 0.2182\n",
      "Epoch 42/50, Loss: 0.2163\n",
      "Epoch 43/50, Loss: 0.2119\n",
      "Epoch 44/50, Loss: 0.2108\n",
      "Epoch 45/50, Loss: 0.2085\n",
      "Epoch 46/50, Loss: 0.2062\n",
      "Epoch 47/50, Loss: 0.2033\n",
      "Epoch 48/50, Loss: 0.2017\n",
      "Epoch 49/50, Loss: 0.1999\n",
      "Epoch 50/50, Loss: 0.1988\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=50, Optimizer=RMSProp\n",
      "Epoch 1/50, Loss: 0.4529\n",
      "Epoch 2/50, Loss: 0.2791\n",
      "Epoch 3/50, Loss: 0.2318\n",
      "Epoch 4/50, Loss: 0.2006\n",
      "Epoch 5/50, Loss: 0.1746\n",
      "Epoch 6/50, Loss: 0.1526\n",
      "Epoch 7/50, Loss: 0.1325\n",
      "Epoch 8/50, Loss: 0.1155\n",
      "Epoch 9/50, Loss: 0.0995\n",
      "Epoch 10/50, Loss: 0.0849\n",
      "Epoch 11/50, Loss: 0.0722\n",
      "Epoch 12/50, Loss: 0.0610\n",
      "Epoch 13/50, Loss: 0.0348\n",
      "Epoch 14/50, Loss: 0.0275\n",
      "Epoch 15/50, Loss: 0.0226\n",
      "Epoch 16/50, Loss: 0.0182\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=50, Optimizer=Adam\n",
      "Epoch 1/50, Loss: 0.4931\n",
      "Epoch 2/50, Loss: 0.3106\n",
      "Epoch 3/50, Loss: 0.2580\n",
      "Epoch 4/50, Loss: 0.2288\n",
      "Epoch 5/50, Loss: 0.2028\n",
      "Epoch 6/50, Loss: 0.1833\n",
      "Epoch 7/50, Loss: 0.1655\n",
      "Epoch 8/50, Loss: 0.1472\n",
      "Epoch 9/50, Loss: 0.1325\n",
      "Epoch 10/50, Loss: 0.1158\n",
      "Epoch 11/50, Loss: 0.1020\n",
      "Epoch 12/50, Loss: 0.0907\n",
      "Epoch 13/50, Loss: 0.0820\n",
      "Epoch 14/50, Loss: 0.0509\n",
      "Epoch 15/50, Loss: 0.0417\n",
      "Epoch 16/50, Loss: 0.0354\n",
      "Epoch 17/50, Loss: 0.0323\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=100, Optimizer=SGD\n",
      "Epoch 1/100, Loss: 1.1363\n",
      "Epoch 2/100, Loss: 0.6216\n",
      "Epoch 3/100, Loss: 0.5506\n",
      "Epoch 4/100, Loss: 0.5033\n",
      "Epoch 5/100, Loss: 0.4654\n",
      "Epoch 6/100, Loss: 0.4398\n",
      "Epoch 7/100, Loss: 0.4162\n",
      "Epoch 8/100, Loss: 0.4006\n",
      "Epoch 9/100, Loss: 0.3849\n",
      "Epoch 10/100, Loss: 0.3729\n",
      "Epoch 11/100, Loss: 0.3626\n",
      "Epoch 12/100, Loss: 0.3515\n",
      "Epoch 13/100, Loss: 0.3448\n",
      "Epoch 14/100, Loss: 0.3362\n",
      "Epoch 15/100, Loss: 0.3295\n",
      "Epoch 16/100, Loss: 0.3218\n",
      "Epoch 17/100, Loss: 0.3159\n",
      "Epoch 18/100, Loss: 0.3101\n",
      "Epoch 19/100, Loss: 0.3062\n",
      "Epoch 20/100, Loss: 0.2997\n",
      "Epoch 21/100, Loss: 0.2947\n",
      "Epoch 22/100, Loss: 0.2899\n",
      "Epoch 23/100, Loss: 0.2843\n",
      "Epoch 24/100, Loss: 0.2797\n",
      "Epoch 25/100, Loss: 0.2770\n",
      "Epoch 26/100, Loss: 0.2725\n",
      "Epoch 27/100, Loss: 0.2681\n",
      "Epoch 28/100, Loss: 0.2651\n",
      "Epoch 29/100, Loss: 0.2620\n",
      "Epoch 30/100, Loss: 0.2582\n",
      "Epoch 31/100, Loss: 0.2546\n",
      "Epoch 32/100, Loss: 0.2515\n",
      "Epoch 33/100, Loss: 0.2490\n",
      "Epoch 34/100, Loss: 0.2467\n",
      "Epoch 35/100, Loss: 0.2425\n",
      "Epoch 36/100, Loss: 0.2396\n",
      "Epoch 37/100, Loss: 0.2379\n",
      "Epoch 38/100, Loss: 0.2345\n",
      "Epoch 39/100, Loss: 0.2321\n",
      "Epoch 40/100, Loss: 0.2305\n",
      "Epoch 41/100, Loss: 0.2264\n",
      "Epoch 42/100, Loss: 0.2250\n",
      "Epoch 43/100, Loss: 0.2218\n",
      "Epoch 44/100, Loss: 0.2192\n",
      "Epoch 45/100, Loss: 0.2184\n",
      "Epoch 46/100, Loss: 0.2152\n",
      "Epoch 47/100, Loss: 0.2126\n",
      "Epoch 48/100, Loss: 0.2096\n",
      "Epoch 49/100, Loss: 0.2094\n",
      "Epoch 50/100, Loss: 0.2073\n",
      "Epoch 51/100, Loss: 0.2046\n",
      "Epoch 52/100, Loss: 0.2028\n",
      "Epoch 53/100, Loss: 0.1995\n",
      "Epoch 54/100, Loss: 0.1981\n",
      "Epoch 55/100, Loss: 0.1961\n",
      "Epoch 56/100, Loss: 0.1948\n",
      "Epoch 57/100, Loss: 0.1935\n",
      "Epoch 58/100, Loss: 0.1919\n",
      "Epoch 59/100, Loss: 0.1900\n",
      "Epoch 60/100, Loss: 0.1871\n",
      "Epoch 61/100, Loss: 0.1860\n",
      "Epoch 62/100, Loss: 0.1731\n",
      "Epoch 63/100, Loss: 0.1713\n",
      "Epoch 64/100, Loss: 0.1699\n",
      "Epoch 65/100, Loss: 0.1692\n",
      "Epoch 66/100, Loss: 0.1682\n",
      "Epoch 67/100, Loss: 0.1670\n",
      "Epoch 68/100, Loss: 0.1661\n",
      "Epoch 69/100, Loss: 0.1643\n",
      "Epoch 70/100, Loss: 0.1642\n",
      "Epoch 71/100, Loss: 0.1630\n",
      "Epoch 72/100, Loss: 0.1620\n",
      "Epoch 73/100, Loss: 0.1612\n",
      "Epoch 74/100, Loss: 0.1600\n",
      "Epoch 75/100, Loss: 0.1540\n",
      "Epoch 76/100, Loss: 0.1533\n",
      "Epoch 77/100, Loss: 0.1526\n",
      "Epoch 78/100, Loss: 0.1518\n",
      "Epoch 79/100, Loss: 0.1514\n",
      "Epoch 80/100, Loss: 0.1507\n",
      "Epoch 81/100, Loss: 0.1502\n",
      "Epoch 82/100, Loss: 0.1498\n",
      "Epoch 83/100, Loss: 0.1490\n",
      "Epoch 84/100, Loss: 0.1489\n",
      "Epoch 85/100, Loss: 0.1481\n",
      "Epoch 86/100, Loss: 0.1475\n",
      "Epoch 87/100, Loss: 0.1468\n",
      "Epoch 88/100, Loss: 0.1460\n",
      "Epoch 89/100, Loss: 0.1460\n",
      "Epoch 90/100, Loss: 0.1431\n",
      "Epoch 91/100, Loss: 0.1425\n",
      "Epoch 92/100, Loss: 0.1421\n",
      "Epoch 93/100, Loss: 0.1419\n",
      "Epoch 94/100, Loss: 0.1416\n",
      "Epoch 95/100, Loss: 0.1413\n",
      "Epoch 96/100, Loss: 0.1410\n",
      "Epoch 97/100, Loss: 0.1406\n",
      "Epoch 98/100, Loss: 0.1405\n",
      "Epoch 99/100, Loss: 0.1399\n",
      "Epoch 100/100, Loss: 0.1400\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=100, Optimizer=RMSProp\n",
      "Epoch 1/100, Loss: 0.5011\n",
      "Epoch 2/100, Loss: 0.3024\n",
      "Epoch 3/100, Loss: 0.2516\n",
      "Epoch 4/100, Loss: 0.2189\n",
      "Epoch 5/100, Loss: 0.1924\n",
      "Epoch 6/100, Loss: 0.1727\n",
      "Epoch 7/100, Loss: 0.1542\n",
      "Epoch 8/100, Loss: 0.1363\n",
      "Epoch 9/100, Loss: 0.1203\n",
      "Epoch 10/100, Loss: 0.1068\n",
      "Epoch 11/100, Loss: 0.0941\n",
      "Epoch 12/100, Loss: 0.0831\n",
      "Epoch 13/100, Loss: 0.0549\n",
      "Epoch 14/100, Loss: 0.0468\n",
      "Epoch 15/100, Loss: 0.0402\n",
      "Epoch 16/100, Loss: 0.0344\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=100, Optimizer=Adam\n",
      "Epoch 1/100, Loss: 0.4984\n",
      "Epoch 2/100, Loss: 0.3179\n",
      "Epoch 3/100, Loss: 0.2703\n",
      "Epoch 4/100, Loss: 0.2337\n",
      "Epoch 5/100, Loss: 0.2097\n",
      "Epoch 6/100, Loss: 0.1870\n",
      "Epoch 7/100, Loss: 0.1687\n",
      "Epoch 8/100, Loss: 0.1518\n",
      "Epoch 9/100, Loss: 0.1359\n",
      "Epoch 10/100, Loss: 0.1222\n",
      "Epoch 11/100, Loss: 0.1064\n",
      "Epoch 12/100, Loss: 0.0929\n",
      "Epoch 13/100, Loss: 0.0623\n",
      "Epoch 14/100, Loss: 0.0539\n",
      "Epoch 15/100, Loss: 0.0462\n",
      "Epoch 16/100, Loss: 0.0415\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=250, Optimizer=SGD\n",
      "Epoch 1/250, Loss: 1.2054\n",
      "Epoch 2/250, Loss: 0.5856\n",
      "Epoch 3/250, Loss: 0.5149\n",
      "Epoch 4/250, Loss: 0.4693\n",
      "Epoch 5/250, Loss: 0.4381\n",
      "Epoch 6/250, Loss: 0.4124\n",
      "Epoch 7/250, Loss: 0.3934\n",
      "Epoch 8/250, Loss: 0.3755\n",
      "Epoch 9/250, Loss: 0.3632\n",
      "Epoch 10/250, Loss: 0.3514\n",
      "Epoch 11/250, Loss: 0.3448\n",
      "Epoch 12/250, Loss: 0.3337\n",
      "Epoch 13/250, Loss: 0.3273\n",
      "Epoch 14/250, Loss: 0.3191\n",
      "Epoch 15/250, Loss: 0.3122\n",
      "Epoch 16/250, Loss: 0.3049\n",
      "Epoch 17/250, Loss: 0.2979\n",
      "Epoch 18/250, Loss: 0.2941\n",
      "Epoch 19/250, Loss: 0.2882\n",
      "Epoch 20/250, Loss: 0.2829\n",
      "Epoch 21/250, Loss: 0.2783\n",
      "Epoch 22/250, Loss: 0.2739\n",
      "Epoch 23/250, Loss: 0.2703\n",
      "Epoch 24/250, Loss: 0.2648\n",
      "Epoch 25/250, Loss: 0.2611\n",
      "Epoch 26/250, Loss: 0.2576\n",
      "Epoch 27/250, Loss: 0.2544\n",
      "Epoch 28/250, Loss: 0.2505\n",
      "Epoch 29/250, Loss: 0.2472\n",
      "Epoch 30/250, Loss: 0.2436\n",
      "Epoch 31/250, Loss: 0.2410\n",
      "Epoch 32/250, Loss: 0.2372\n",
      "Epoch 33/250, Loss: 0.2340\n",
      "Epoch 34/250, Loss: 0.2321\n",
      "Epoch 35/250, Loss: 0.2289\n",
      "Epoch 36/250, Loss: 0.2257\n",
      "Epoch 37/250, Loss: 0.2228\n",
      "Epoch 38/250, Loss: 0.2210\n",
      "Epoch 39/250, Loss: 0.2176\n",
      "Epoch 40/250, Loss: 0.2167\n",
      "Epoch 41/250, Loss: 0.2142\n",
      "Epoch 42/250, Loss: 0.2105\n",
      "Epoch 43/250, Loss: 0.2084\n",
      "Epoch 44/250, Loss: 0.2063\n",
      "Epoch 45/250, Loss: 0.2043\n",
      "Epoch 46/250, Loss: 0.2018\n",
      "Epoch 47/250, Loss: 0.1995\n",
      "Epoch 48/250, Loss: 0.1972\n",
      "Epoch 49/250, Loss: 0.1859\n",
      "Epoch 50/250, Loss: 0.1847\n",
      "Epoch 51/250, Loss: 0.1834\n",
      "Epoch 52/250, Loss: 0.1816\n",
      "Epoch 53/250, Loss: 0.1810\n",
      "Epoch 54/250, Loss: 0.1797\n",
      "Epoch 55/250, Loss: 0.1786\n",
      "Epoch 56/250, Loss: 0.1775\n",
      "Epoch 57/250, Loss: 0.1764\n",
      "Epoch 58/250, Loss: 0.1752\n",
      "Epoch 59/250, Loss: 0.1744\n",
      "Epoch 60/250, Loss: 0.1729\n",
      "Epoch 61/250, Loss: 0.1728\n",
      "Epoch 62/250, Loss: 0.1712\n",
      "Epoch 63/250, Loss: 0.1700\n",
      "Epoch 64/250, Loss: 0.1641\n",
      "Epoch 65/250, Loss: 0.1632\n",
      "Epoch 66/250, Loss: 0.1627\n",
      "Epoch 67/250, Loss: 0.1622\n",
      "Epoch 68/250, Loss: 0.1611\n",
      "Epoch 69/250, Loss: 0.1607\n",
      "Epoch 70/250, Loss: 0.1603\n",
      "Epoch 71/250, Loss: 0.1597\n",
      "Epoch 72/250, Loss: 0.1592\n",
      "Epoch 73/250, Loss: 0.1585\n",
      "Epoch 74/250, Loss: 0.1585\n",
      "Epoch 75/250, Loss: 0.1577\n",
      "Epoch 76/250, Loss: 0.1568\n",
      "Epoch 77/250, Loss: 0.1563\n",
      "Epoch 78/250, Loss: 0.1559\n",
      "Epoch 79/250, Loss: 0.1552\n",
      "Epoch 80/250, Loss: 0.1547\n",
      "Epoch 81/250, Loss: 0.1543\n",
      "Epoch 82/250, Loss: 0.1535\n",
      "Epoch 83/250, Loss: 0.1532\n",
      "Epoch 84/250, Loss: 0.1501\n",
      "Epoch 85/250, Loss: 0.1496\n",
      "Epoch 86/250, Loss: 0.1493\n",
      "Epoch 87/250, Loss: 0.1489\n",
      "Epoch 88/250, Loss: 0.1489\n",
      "Epoch 89/250, Loss: 0.1483\n",
      "Epoch 90/250, Loss: 0.1481\n",
      "Epoch 91/250, Loss: 0.1479\n",
      "Epoch 92/250, Loss: 0.1476\n",
      "Epoch 93/250, Loss: 0.1472\n",
      "Epoch 94/250, Loss: 0.1469\n",
      "Epoch 95/250, Loss: 0.1455\n",
      "Epoch 96/250, Loss: 0.1453\n",
      "Epoch 97/250, Loss: 0.1451\n",
      "Epoch 98/250, Loss: 0.1448\n",
      "Epoch 99/250, Loss: 0.1447\n",
      "Epoch 100/250, Loss: 0.1445\n",
      "Epoch 101/250, Loss: 0.1443\n",
      "Epoch 102/250, Loss: 0.1442\n",
      "Epoch 103/250, Loss: 0.1441\n",
      "Epoch 104/250, Loss: 0.1434\n",
      "Epoch 105/250, Loss: 0.1432\n",
      "Epoch 106/250, Loss: 0.1431\n",
      "Epoch 107/250, Loss: 0.1430\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=250, Optimizer=RMSProp\n",
      "Epoch 1/250, Loss: 0.4687\n",
      "Epoch 2/250, Loss: 0.2899\n",
      "Epoch 3/250, Loss: 0.2439\n",
      "Epoch 4/250, Loss: 0.2109\n",
      "Epoch 5/250, Loss: 0.1881\n",
      "Epoch 6/250, Loss: 0.1666\n",
      "Epoch 7/250, Loss: 0.1470\n",
      "Epoch 8/250, Loss: 0.1303\n",
      "Epoch 9/250, Loss: 0.1155\n",
      "Epoch 10/250, Loss: 0.1009\n",
      "Epoch 11/250, Loss: 0.0880\n",
      "Epoch 12/250, Loss: 0.0753\n",
      "Epoch 13/250, Loss: 0.0664\n",
      "Epoch 14/250, Loss: 0.0392\n",
      "Epoch 15/250, Loss: 0.0322\n",
      "Epoch 16/250, Loss: 0.0267\n",
      "Epoch 17/250, Loss: 0.0222\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=250, Optimizer=Adam\n",
      "Epoch 1/250, Loss: 0.4819\n",
      "Epoch 2/250, Loss: 0.3062\n",
      "Epoch 3/250, Loss: 0.2574\n",
      "Epoch 4/250, Loss: 0.2270\n",
      "Epoch 5/250, Loss: 0.2037\n",
      "Epoch 6/250, Loss: 0.1823\n",
      "Epoch 7/250, Loss: 0.1641\n",
      "Epoch 8/250, Loss: 0.1471\n",
      "Epoch 9/250, Loss: 0.1311\n",
      "Epoch 10/250, Loss: 0.1137\n",
      "Epoch 11/250, Loss: 0.1006\n",
      "Epoch 12/250, Loss: 0.0879\n",
      "Epoch 13/250, Loss: 0.0774\n",
      "Epoch 14/250, Loss: 0.0491\n",
      "Epoch 15/250, Loss: 0.0394\n",
      "Epoch 16/250, Loss: 0.0354\n",
      "Epoch 17/250, Loss: 0.0302\n",
      "Epoch 18/250, Loss: 0.0263\n",
      "Epoch 19/250, Loss: 0.0222\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=350, Optimizer=SGD\n",
      "Epoch 1/350, Loss: 1.0683\n",
      "Epoch 2/350, Loss: 0.6215\n",
      "Epoch 3/350, Loss: 0.5546\n",
      "Epoch 4/350, Loss: 0.5081\n",
      "Epoch 5/350, Loss: 0.4697\n",
      "Epoch 6/350, Loss: 0.4394\n",
      "Epoch 7/350, Loss: 0.4153\n",
      "Epoch 8/350, Loss: 0.3992\n",
      "Epoch 9/350, Loss: 0.3818\n",
      "Epoch 10/350, Loss: 0.3700\n",
      "Epoch 11/350, Loss: 0.3581\n",
      "Epoch 12/350, Loss: 0.3473\n",
      "Epoch 13/350, Loss: 0.3393\n",
      "Epoch 14/350, Loss: 0.3301\n",
      "Epoch 15/350, Loss: 0.3222\n",
      "Epoch 16/350, Loss: 0.3147\n",
      "Epoch 17/350, Loss: 0.3087\n",
      "Epoch 18/350, Loss: 0.3040\n",
      "Epoch 19/350, Loss: 0.2972\n",
      "Epoch 20/350, Loss: 0.2912\n",
      "Epoch 21/350, Loss: 0.2870\n",
      "Epoch 22/350, Loss: 0.2824\n",
      "Epoch 23/350, Loss: 0.2773\n",
      "Epoch 24/350, Loss: 0.2723\n",
      "Epoch 25/350, Loss: 0.2695\n",
      "Epoch 26/350, Loss: 0.2649\n",
      "Epoch 27/350, Loss: 0.2618\n",
      "Epoch 28/350, Loss: 0.2581\n",
      "Epoch 29/350, Loss: 0.2542\n",
      "Epoch 30/350, Loss: 0.2500\n",
      "Epoch 31/350, Loss: 0.2474\n",
      "Epoch 32/350, Loss: 0.2447\n",
      "Epoch 33/350, Loss: 0.2408\n",
      "Epoch 34/350, Loss: 0.2381\n",
      "Epoch 35/350, Loss: 0.2351\n",
      "Epoch 36/350, Loss: 0.2334\n",
      "Epoch 37/350, Loss: 0.2290\n",
      "Epoch 38/350, Loss: 0.2274\n",
      "Epoch 39/350, Loss: 0.2239\n",
      "Epoch 40/350, Loss: 0.2239\n",
      "Epoch 41/350, Loss: 0.2187\n",
      "Epoch 42/350, Loss: 0.2170\n",
      "Epoch 43/350, Loss: 0.2150\n",
      "Epoch 44/350, Loss: 0.2112\n",
      "Epoch 45/350, Loss: 0.2104\n",
      "Epoch 46/350, Loss: 0.2079\n",
      "Epoch 47/350, Loss: 0.2052\n",
      "Epoch 48/350, Loss: 0.2035\n",
      "Epoch 49/350, Loss: 0.2016\n",
      "Epoch 50/350, Loss: 0.1997\n",
      "Epoch 51/350, Loss: 0.1983\n",
      "Epoch 52/350, Loss: 0.1954\n",
      "Epoch 53/350, Loss: 0.1937\n",
      "Epoch 54/350, Loss: 0.1914\n",
      "Epoch 55/350, Loss: 0.1906\n",
      "Epoch 56/350, Loss: 0.1878\n",
      "Epoch 57/350, Loss: 0.1856\n",
      "Epoch 58/350, Loss: 0.1844\n",
      "Epoch 59/350, Loss: 0.1828\n",
      "Epoch 60/350, Loss: 0.1810\n",
      "Epoch 61/350, Loss: 0.1788\n",
      "Epoch 62/350, Loss: 0.1766\n",
      "Epoch 63/350, Loss: 0.1755\n",
      "Epoch 64/350, Loss: 0.1746\n",
      "Epoch 65/350, Loss: 0.1718\n",
      "Epoch 66/350, Loss: 0.1706\n",
      "Epoch 67/350, Loss: 0.1577\n",
      "Epoch 68/350, Loss: 0.1557\n",
      "Epoch 69/350, Loss: 0.1551\n",
      "Epoch 70/350, Loss: 0.1538\n",
      "Epoch 71/350, Loss: 0.1528\n",
      "Epoch 72/350, Loss: 0.1521\n",
      "Epoch 73/350, Loss: 0.1508\n",
      "Epoch 74/350, Loss: 0.1498\n",
      "Epoch 75/350, Loss: 0.1491\n",
      "Epoch 76/350, Loss: 0.1483\n",
      "Epoch 77/350, Loss: 0.1478\n",
      "Epoch 78/350, Loss: 0.1414\n",
      "Epoch 79/350, Loss: 0.1410\n",
      "Epoch 80/350, Loss: 0.1398\n",
      "Epoch 81/350, Loss: 0.1396\n",
      "Epoch 82/350, Loss: 0.1388\n",
      "Epoch 83/350, Loss: 0.1387\n",
      "Epoch 84/350, Loss: 0.1381\n",
      "Epoch 85/350, Loss: 0.1353\n",
      "Epoch 86/350, Loss: 0.1349\n",
      "Epoch 87/350, Loss: 0.1345\n",
      "Epoch 88/350, Loss: 0.1343\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=350, Optimizer=RMSProp\n",
      "Epoch 1/350, Loss: 0.5117\n",
      "Epoch 2/350, Loss: 0.3143\n",
      "Epoch 3/350, Loss: 0.2635\n",
      "Epoch 4/350, Loss: 0.2321\n",
      "Epoch 5/350, Loss: 0.2081\n",
      "Epoch 6/350, Loss: 0.1878\n",
      "Epoch 7/350, Loss: 0.1705\n",
      "Epoch 8/350, Loss: 0.1540\n",
      "Epoch 9/350, Loss: 0.1379\n",
      "Epoch 10/350, Loss: 0.1263\n",
      "Epoch 11/350, Loss: 0.1107\n",
      "Epoch 12/350, Loss: 0.0996\n",
      "Epoch 13/350, Loss: 0.0711\n",
      "Epoch 14/350, Loss: 0.0620\n",
      "Epoch 15/350, Loss: 0.0548\n",
      "Epoch 16/350, Loss: 0.0484\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=max, Epochs=350, Optimizer=Adam\n",
      "Epoch 1/350, Loss: 0.4728\n",
      "Epoch 2/350, Loss: 0.2992\n",
      "Epoch 3/350, Loss: 0.2521\n",
      "Epoch 4/350, Loss: 0.2184\n",
      "Epoch 5/350, Loss: 0.2007\n",
      "Epoch 6/350, Loss: 0.1774\n",
      "Epoch 7/350, Loss: 0.1592\n",
      "Epoch 8/350, Loss: 0.1432\n",
      "Epoch 9/350, Loss: 0.1268\n",
      "Epoch 10/350, Loss: 0.1136\n",
      "Epoch 11/350, Loss: 0.1001\n",
      "Epoch 12/350, Loss: 0.0843\n",
      "Epoch 13/350, Loss: 0.0711\n",
      "Epoch 14/350, Loss: 0.0448\n",
      "Epoch 15/350, Loss: 0.0366\n",
      "Epoch 16/350, Loss: 0.0323\n",
      "Epoch 17/350, Loss: 0.0278\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=5, Optimizer=SGD\n",
      "Epoch 1/5, Loss: 1.1378\n",
      "Epoch 2/5, Loss: 0.6663\n",
      "Epoch 3/5, Loss: 0.6104\n",
      "Epoch 4/5, Loss: 0.5762\n",
      "Epoch 5/5, Loss: 0.5485\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=5, Optimizer=RMSProp\n",
      "Epoch 1/5, Loss: 0.5081\n",
      "Epoch 2/5, Loss: 0.3315\n",
      "Epoch 3/5, Loss: 0.2806\n",
      "Epoch 4/5, Loss: 0.2493\n",
      "Epoch 5/5, Loss: 0.2229\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=5, Optimizer=Adam\n",
      "Epoch 1/5, Loss: 0.5357\n",
      "Epoch 2/5, Loss: 0.3440\n",
      "Epoch 3/5, Loss: 0.2978\n",
      "Epoch 4/5, Loss: 0.2659\n",
      "Epoch 5/5, Loss: 0.2414\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=50, Optimizer=SGD\n",
      "Epoch 1/50, Loss: 1.2936\n",
      "Epoch 2/50, Loss: 0.6775\n",
      "Epoch 3/50, Loss: 0.6174\n",
      "Epoch 4/50, Loss: 0.5812\n",
      "Epoch 5/50, Loss: 0.5503\n",
      "Epoch 6/50, Loss: 0.5260\n",
      "Epoch 7/50, Loss: 0.5051\n",
      "Epoch 8/50, Loss: 0.4885\n",
      "Epoch 9/50, Loss: 0.4699\n",
      "Epoch 10/50, Loss: 0.4571\n",
      "Epoch 11/50, Loss: 0.4438\n",
      "Epoch 12/50, Loss: 0.4333\n",
      "Epoch 13/50, Loss: 0.4228\n",
      "Epoch 14/50, Loss: 0.4149\n",
      "Epoch 15/50, Loss: 0.4048\n",
      "Epoch 16/50, Loss: 0.4001\n",
      "Epoch 17/50, Loss: 0.3914\n",
      "Epoch 18/50, Loss: 0.3855\n",
      "Epoch 19/50, Loss: 0.3788\n",
      "Epoch 20/50, Loss: 0.3765\n",
      "Epoch 21/50, Loss: 0.3667\n",
      "Epoch 22/50, Loss: 0.3631\n",
      "Epoch 23/50, Loss: 0.3603\n",
      "Epoch 24/50, Loss: 0.3541\n",
      "Epoch 25/50, Loss: 0.3498\n",
      "Epoch 26/50, Loss: 0.3452\n",
      "Epoch 27/50, Loss: 0.3420\n",
      "Epoch 28/50, Loss: 0.3383\n",
      "Epoch 29/50, Loss: 0.3340\n",
      "Epoch 30/50, Loss: 0.3301\n",
      "Epoch 31/50, Loss: 0.3280\n",
      "Epoch 32/50, Loss: 0.3256\n",
      "Epoch 33/50, Loss: 0.3206\n",
      "Epoch 34/50, Loss: 0.3177\n",
      "Epoch 35/50, Loss: 0.3155\n",
      "Epoch 36/50, Loss: 0.3119\n",
      "Epoch 37/50, Loss: 0.3095\n",
      "Epoch 38/50, Loss: 0.3084\n",
      "Epoch 39/50, Loss: 0.3041\n",
      "Epoch 40/50, Loss: 0.3026\n",
      "Epoch 41/50, Loss: 0.2997\n",
      "Epoch 42/50, Loss: 0.2979\n",
      "Epoch 43/50, Loss: 0.2956\n",
      "Epoch 44/50, Loss: 0.2925\n",
      "Epoch 45/50, Loss: 0.2907\n",
      "Epoch 46/50, Loss: 0.2890\n",
      "Epoch 47/50, Loss: 0.2858\n",
      "Epoch 48/50, Loss: 0.2838\n",
      "Epoch 49/50, Loss: 0.2829\n",
      "Epoch 50/50, Loss: 0.2801\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=50, Optimizer=RMSProp\n",
      "Epoch 1/50, Loss: 0.5536\n",
      "Epoch 2/50, Loss: 0.3450\n",
      "Epoch 3/50, Loss: 0.2905\n",
      "Epoch 4/50, Loss: 0.2589\n",
      "Epoch 5/50, Loss: 0.2325\n",
      "Epoch 6/50, Loss: 0.2124\n",
      "Epoch 7/50, Loss: 0.1960\n",
      "Epoch 8/50, Loss: 0.1825\n",
      "Epoch 9/50, Loss: 0.1695\n",
      "Epoch 10/50, Loss: 0.1574\n",
      "Epoch 11/50, Loss: 0.1475\n",
      "Epoch 12/50, Loss: 0.1369\n",
      "Epoch 13/50, Loss: 0.1276\n",
      "Epoch 14/50, Loss: 0.1184\n",
      "Epoch 15/50, Loss: 0.1103\n",
      "Epoch 16/50, Loss: 0.1023\n",
      "Epoch 17/50, Loss: 0.0940\n",
      "Epoch 18/50, Loss: 0.0864\n",
      "Epoch 19/50, Loss: 0.0641\n",
      "Epoch 20/50, Loss: 0.0588\n",
      "Epoch 21/50, Loss: 0.0540\n",
      "Epoch 22/50, Loss: 0.0498\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=50, Optimizer=Adam\n",
      "Epoch 1/50, Loss: 0.5298\n",
      "Epoch 2/50, Loss: 0.3363\n",
      "Epoch 3/50, Loss: 0.2860\n",
      "Epoch 4/50, Loss: 0.2551\n",
      "Epoch 5/50, Loss: 0.2342\n",
      "Epoch 6/50, Loss: 0.2168\n",
      "Epoch 7/50, Loss: 0.2015\n",
      "Epoch 8/50, Loss: 0.1869\n",
      "Epoch 9/50, Loss: 0.1775\n",
      "Epoch 10/50, Loss: 0.1656\n",
      "Epoch 11/50, Loss: 0.1535\n",
      "Epoch 12/50, Loss: 0.1421\n",
      "Epoch 13/50, Loss: 0.1341\n",
      "Epoch 14/50, Loss: 0.1229\n",
      "Epoch 15/50, Loss: 0.1118\n",
      "Epoch 16/50, Loss: 0.1041\n",
      "Epoch 17/50, Loss: 0.0945\n",
      "Epoch 18/50, Loss: 0.0709\n",
      "Epoch 19/50, Loss: 0.0638\n",
      "Epoch 20/50, Loss: 0.0583\n",
      "Epoch 21/50, Loss: 0.0558\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=100, Optimizer=SGD\n",
      "Epoch 1/100, Loss: 1.4633\n",
      "Epoch 2/100, Loss: 0.6867\n",
      "Epoch 3/100, Loss: 0.6238\n",
      "Epoch 4/100, Loss: 0.5907\n",
      "Epoch 5/100, Loss: 0.5605\n",
      "Epoch 6/100, Loss: 0.5400\n",
      "Epoch 7/100, Loss: 0.5204\n",
      "Epoch 8/100, Loss: 0.5000\n",
      "Epoch 9/100, Loss: 0.4825\n",
      "Epoch 10/100, Loss: 0.4696\n",
      "Epoch 11/100, Loss: 0.4547\n",
      "Epoch 12/100, Loss: 0.4427\n",
      "Epoch 13/100, Loss: 0.4336\n",
      "Epoch 14/100, Loss: 0.4253\n",
      "Epoch 15/100, Loss: 0.4160\n",
      "Epoch 16/100, Loss: 0.4079\n",
      "Epoch 17/100, Loss: 0.4009\n",
      "Epoch 18/100, Loss: 0.3952\n",
      "Epoch 19/100, Loss: 0.3883\n",
      "Epoch 20/100, Loss: 0.3809\n",
      "Epoch 21/100, Loss: 0.3788\n",
      "Epoch 22/100, Loss: 0.3702\n",
      "Epoch 23/100, Loss: 0.3674\n",
      "Epoch 24/100, Loss: 0.3634\n",
      "Epoch 25/100, Loss: 0.3560\n",
      "Epoch 26/100, Loss: 0.3541\n",
      "Epoch 27/100, Loss: 0.3491\n",
      "Epoch 28/100, Loss: 0.3449\n",
      "Epoch 29/100, Loss: 0.3420\n",
      "Epoch 30/100, Loss: 0.3382\n",
      "Epoch 31/100, Loss: 0.3348\n",
      "Epoch 32/100, Loss: 0.3293\n",
      "Epoch 33/100, Loss: 0.3264\n",
      "Epoch 34/100, Loss: 0.3252\n",
      "Epoch 35/100, Loss: 0.3218\n",
      "Epoch 36/100, Loss: 0.3186\n",
      "Epoch 37/100, Loss: 0.3157\n",
      "Epoch 38/100, Loss: 0.3135\n",
      "Epoch 39/100, Loss: 0.3105\n",
      "Epoch 40/100, Loss: 0.3081\n",
      "Epoch 41/100, Loss: 0.3053\n",
      "Epoch 42/100, Loss: 0.3025\n",
      "Epoch 43/100, Loss: 0.3005\n",
      "Epoch 44/100, Loss: 0.2987\n",
      "Epoch 45/100, Loss: 0.2947\n",
      "Epoch 46/100, Loss: 0.2941\n",
      "Epoch 47/100, Loss: 0.2911\n",
      "Epoch 48/100, Loss: 0.2891\n",
      "Epoch 49/100, Loss: 0.2869\n",
      "Epoch 50/100, Loss: 0.2847\n",
      "Epoch 51/100, Loss: 0.2827\n",
      "Epoch 52/100, Loss: 0.2813\n",
      "Epoch 53/100, Loss: 0.2801\n",
      "Epoch 54/100, Loss: 0.2776\n",
      "Epoch 55/100, Loss: 0.2759\n",
      "Epoch 56/100, Loss: 0.2733\n",
      "Epoch 57/100, Loss: 0.2722\n",
      "Epoch 58/100, Loss: 0.2703\n",
      "Epoch 59/100, Loss: 0.2689\n",
      "Epoch 60/100, Loss: 0.2676\n",
      "Epoch 61/100, Loss: 0.2652\n",
      "Epoch 62/100, Loss: 0.2635\n",
      "Epoch 63/100, Loss: 0.2615\n",
      "Epoch 64/100, Loss: 0.2609\n",
      "Epoch 65/100, Loss: 0.2586\n",
      "Epoch 66/100, Loss: 0.2566\n",
      "Epoch 67/100, Loss: 0.2558\n",
      "Epoch 68/100, Loss: 0.2541\n",
      "Epoch 69/100, Loss: 0.2533\n",
      "Epoch 70/100, Loss: 0.2519\n",
      "Epoch 71/100, Loss: 0.2497\n",
      "Epoch 72/100, Loss: 0.2482\n",
      "Epoch 73/100, Loss: 0.2474\n",
      "Epoch 74/100, Loss: 0.2457\n",
      "Epoch 75/100, Loss: 0.2438\n",
      "Epoch 76/100, Loss: 0.2428\n",
      "Epoch 77/100, Loss: 0.2415\n",
      "Epoch 78/100, Loss: 0.2404\n",
      "Epoch 79/100, Loss: 0.2387\n",
      "Epoch 80/100, Loss: 0.2375\n",
      "Epoch 81/100, Loss: 0.2367\n",
      "Epoch 82/100, Loss: 0.2349\n",
      "Epoch 83/100, Loss: 0.2349\n",
      "Epoch 84/100, Loss: 0.2331\n",
      "Epoch 85/100, Loss: 0.2310\n",
      "Epoch 86/100, Loss: 0.2312\n",
      "Epoch 87/100, Loss: 0.2282\n",
      "Epoch 88/100, Loss: 0.2282\n",
      "Epoch 89/100, Loss: 0.2264\n",
      "Epoch 90/100, Loss: 0.2252\n",
      "Epoch 91/100, Loss: 0.2247\n",
      "Epoch 92/100, Loss: 0.2233\n",
      "Epoch 93/100, Loss: 0.2221\n",
      "Epoch 94/100, Loss: 0.2214\n",
      "Epoch 95/100, Loss: 0.2193\n",
      "Epoch 96/100, Loss: 0.2191\n",
      "Epoch 97/100, Loss: 0.2179\n",
      "Epoch 98/100, Loss: 0.2165\n",
      "Epoch 99/100, Loss: 0.2162\n",
      "Epoch 100/100, Loss: 0.2144\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=100, Optimizer=RMSProp\n",
      "Epoch 1/100, Loss: 0.4909\n",
      "Epoch 2/100, Loss: 0.3198\n",
      "Epoch 3/100, Loss: 0.2698\n",
      "Epoch 4/100, Loss: 0.2401\n",
      "Epoch 5/100, Loss: 0.2178\n",
      "Epoch 6/100, Loss: 0.1993\n",
      "Epoch 7/100, Loss: 0.1833\n",
      "Epoch 8/100, Loss: 0.1694\n",
      "Epoch 9/100, Loss: 0.1577\n",
      "Epoch 10/100, Loss: 0.1459\n",
      "Epoch 11/100, Loss: 0.1333\n",
      "Epoch 12/100, Loss: 0.1233\n",
      "Epoch 13/100, Loss: 0.1155\n",
      "Epoch 14/100, Loss: 0.1048\n",
      "Epoch 15/100, Loss: 0.0968\n",
      "Epoch 16/100, Loss: 0.0721\n",
      "Epoch 17/100, Loss: 0.0654\n",
      "Epoch 18/100, Loss: 0.0598\n",
      "Epoch 19/100, Loss: 0.0545\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=100, Optimizer=Adam\n",
      "Epoch 1/100, Loss: 0.5250\n",
      "Epoch 2/100, Loss: 0.3374\n",
      "Epoch 3/100, Loss: 0.2897\n",
      "Epoch 4/100, Loss: 0.2579\n",
      "Epoch 5/100, Loss: 0.2326\n",
      "Epoch 6/100, Loss: 0.2151\n",
      "Epoch 7/100, Loss: 0.1985\n",
      "Epoch 8/100, Loss: 0.1880\n",
      "Epoch 9/100, Loss: 0.1728\n",
      "Epoch 10/100, Loss: 0.1616\n",
      "Epoch 11/100, Loss: 0.1506\n",
      "Epoch 12/100, Loss: 0.1405\n",
      "Epoch 13/100, Loss: 0.1300\n",
      "Epoch 14/100, Loss: 0.1196\n",
      "Epoch 15/100, Loss: 0.1117\n",
      "Epoch 16/100, Loss: 0.1014\n",
      "Epoch 17/100, Loss: 0.0923\n",
      "Epoch 18/100, Loss: 0.0693\n",
      "Epoch 19/100, Loss: 0.0627\n",
      "Epoch 20/100, Loss: 0.0585\n",
      "Epoch 21/100, Loss: 0.0533\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=250, Optimizer=SGD\n",
      "Epoch 1/250, Loss: 1.4659\n",
      "Epoch 2/250, Loss: 0.6840\n",
      "Epoch 3/250, Loss: 0.6142\n",
      "Epoch 4/250, Loss: 0.5740\n",
      "Epoch 5/250, Loss: 0.5420\n",
      "Epoch 6/250, Loss: 0.5184\n",
      "Epoch 7/250, Loss: 0.4963\n",
      "Epoch 8/250, Loss: 0.4792\n",
      "Epoch 9/250, Loss: 0.4652\n",
      "Epoch 10/250, Loss: 0.4502\n",
      "Epoch 11/250, Loss: 0.4399\n",
      "Epoch 12/250, Loss: 0.4287\n",
      "Epoch 13/250, Loss: 0.4179\n",
      "Epoch 14/250, Loss: 0.4102\n",
      "Epoch 15/250, Loss: 0.4044\n",
      "Epoch 16/250, Loss: 0.3964\n",
      "Epoch 17/250, Loss: 0.3894\n",
      "Epoch 18/250, Loss: 0.3831\n",
      "Epoch 19/250, Loss: 0.3795\n",
      "Epoch 20/250, Loss: 0.3724\n",
      "Epoch 21/250, Loss: 0.3666\n",
      "Epoch 22/250, Loss: 0.3624\n",
      "Epoch 23/250, Loss: 0.3596\n",
      "Epoch 24/250, Loss: 0.3538\n",
      "Epoch 25/250, Loss: 0.3500\n",
      "Epoch 26/250, Loss: 0.3475\n",
      "Epoch 27/250, Loss: 0.3419\n",
      "Epoch 28/250, Loss: 0.3389\n",
      "Epoch 29/250, Loss: 0.3357\n",
      "Epoch 30/250, Loss: 0.3324\n",
      "Epoch 31/250, Loss: 0.3288\n",
      "Epoch 32/250, Loss: 0.3251\n",
      "Epoch 33/250, Loss: 0.3226\n",
      "Epoch 34/250, Loss: 0.3190\n",
      "Epoch 35/250, Loss: 0.3174\n",
      "Epoch 36/250, Loss: 0.3146\n",
      "Epoch 37/250, Loss: 0.3109\n",
      "Epoch 38/250, Loss: 0.3088\n",
      "Epoch 39/250, Loss: 0.3059\n",
      "Epoch 40/250, Loss: 0.3033\n",
      "Epoch 41/250, Loss: 0.3020\n",
      "Epoch 42/250, Loss: 0.2990\n",
      "Epoch 43/250, Loss: 0.2958\n",
      "Epoch 44/250, Loss: 0.2937\n",
      "Epoch 45/250, Loss: 0.2916\n",
      "Epoch 46/250, Loss: 0.2894\n",
      "Epoch 47/250, Loss: 0.2871\n",
      "Epoch 48/250, Loss: 0.2842\n",
      "Epoch 49/250, Loss: 0.2844\n",
      "Epoch 50/250, Loss: 0.2802\n",
      "Epoch 51/250, Loss: 0.2793\n",
      "Epoch 52/250, Loss: 0.2760\n",
      "Epoch 53/250, Loss: 0.2749\n",
      "Epoch 54/250, Loss: 0.2723\n",
      "Epoch 55/250, Loss: 0.2707\n",
      "Epoch 56/250, Loss: 0.2695\n",
      "Epoch 57/250, Loss: 0.2685\n",
      "Epoch 58/250, Loss: 0.2653\n",
      "Epoch 59/250, Loss: 0.2634\n",
      "Epoch 60/250, Loss: 0.2611\n",
      "Epoch 61/250, Loss: 0.2607\n",
      "Epoch 62/250, Loss: 0.2575\n",
      "Epoch 63/250, Loss: 0.2568\n",
      "Epoch 64/250, Loss: 0.2552\n",
      "Epoch 65/250, Loss: 0.2526\n",
      "Epoch 66/250, Loss: 0.2510\n",
      "Epoch 67/250, Loss: 0.2500\n",
      "Epoch 68/250, Loss: 0.2479\n",
      "Epoch 69/250, Loss: 0.2468\n",
      "Epoch 70/250, Loss: 0.2455\n",
      "Epoch 71/250, Loss: 0.2441\n",
      "Epoch 72/250, Loss: 0.2433\n",
      "Epoch 73/250, Loss: 0.2409\n",
      "Epoch 74/250, Loss: 0.2389\n",
      "Epoch 75/250, Loss: 0.2381\n",
      "Epoch 76/250, Loss: 0.2357\n",
      "Epoch 77/250, Loss: 0.2347\n",
      "Epoch 78/250, Loss: 0.2333\n",
      "Epoch 79/250, Loss: 0.2311\n",
      "Epoch 80/250, Loss: 0.2315\n",
      "Epoch 81/250, Loss: 0.2296\n",
      "Epoch 82/250, Loss: 0.2289\n",
      "Epoch 83/250, Loss: 0.2274\n",
      "Epoch 84/250, Loss: 0.2253\n",
      "Epoch 85/250, Loss: 0.2238\n",
      "Epoch 86/250, Loss: 0.2224\n",
      "Epoch 87/250, Loss: 0.2212\n",
      "Epoch 88/250, Loss: 0.2206\n",
      "Epoch 89/250, Loss: 0.2185\n",
      "Epoch 90/250, Loss: 0.2179\n",
      "Epoch 91/250, Loss: 0.2167\n",
      "Epoch 92/250, Loss: 0.2154\n",
      "Epoch 93/250, Loss: 0.2150\n",
      "Epoch 94/250, Loss: 0.2136\n",
      "Epoch 95/250, Loss: 0.2122\n",
      "Epoch 96/250, Loss: 0.2116\n",
      "Epoch 97/250, Loss: 0.2108\n",
      "Epoch 98/250, Loss: 0.2092\n",
      "Epoch 99/250, Loss: 0.2078\n",
      "Epoch 100/250, Loss: 0.2069\n",
      "Epoch 101/250, Loss: 0.2050\n",
      "Epoch 102/250, Loss: 0.2036\n",
      "Epoch 103/250, Loss: 0.2044\n",
      "Epoch 104/250, Loss: 0.2017\n",
      "Epoch 105/250, Loss: 0.2020\n",
      "Epoch 106/250, Loss: 0.2000\n",
      "Epoch 107/250, Loss: 0.1991\n",
      "Epoch 108/250, Loss: 0.1983\n",
      "Epoch 109/250, Loss: 0.1973\n",
      "Epoch 110/250, Loss: 0.1957\n",
      "Epoch 111/250, Loss: 0.1951\n",
      "Epoch 112/250, Loss: 0.1942\n",
      "Epoch 113/250, Loss: 0.1929\n",
      "Epoch 114/250, Loss: 0.1823\n",
      "Epoch 115/250, Loss: 0.1814\n",
      "Epoch 116/250, Loss: 0.1808\n",
      "Epoch 117/250, Loss: 0.1803\n",
      "Epoch 118/250, Loss: 0.1800\n",
      "Epoch 119/250, Loss: 0.1789\n",
      "Epoch 120/250, Loss: 0.1781\n",
      "Epoch 121/250, Loss: 0.1782\n",
      "Epoch 122/250, Loss: 0.1725\n",
      "Epoch 123/250, Loss: 0.1723\n",
      "Epoch 124/250, Loss: 0.1717\n",
      "Epoch 125/250, Loss: 0.1711\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=250, Optimizer=RMSProp\n",
      "Epoch 1/250, Loss: 0.5564\n",
      "Epoch 2/250, Loss: 0.3525\n",
      "Epoch 3/250, Loss: 0.2982\n",
      "Epoch 4/250, Loss: 0.2629\n",
      "Epoch 5/250, Loss: 0.2393\n",
      "Epoch 6/250, Loss: 0.2195\n",
      "Epoch 7/250, Loss: 0.2027\n",
      "Epoch 8/250, Loss: 0.1885\n",
      "Epoch 9/250, Loss: 0.1779\n",
      "Epoch 10/250, Loss: 0.1653\n",
      "Epoch 11/250, Loss: 0.1557\n",
      "Epoch 12/250, Loss: 0.1460\n",
      "Epoch 13/250, Loss: 0.1357\n",
      "Epoch 14/250, Loss: 0.1270\n",
      "Epoch 15/250, Loss: 0.1179\n",
      "Epoch 16/250, Loss: 0.1117\n",
      "Epoch 17/250, Loss: 0.1027\n",
      "Epoch 18/250, Loss: 0.0807\n",
      "Epoch 19/250, Loss: 0.0745\n",
      "Epoch 20/250, Loss: 0.0705\n",
      "Epoch 21/250, Loss: 0.0657\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=250, Optimizer=Adam\n",
      "Epoch 1/250, Loss: 0.5252\n",
      "Epoch 2/250, Loss: 0.3408\n",
      "Epoch 3/250, Loss: 0.2912\n",
      "Epoch 4/250, Loss: 0.2595\n",
      "Epoch 5/250, Loss: 0.2385\n",
      "Epoch 6/250, Loss: 0.2220\n",
      "Epoch 7/250, Loss: 0.2052\n",
      "Epoch 8/250, Loss: 0.1915\n",
      "Epoch 9/250, Loss: 0.1791\n",
      "Epoch 10/250, Loss: 0.1691\n",
      "Epoch 11/250, Loss: 0.1577\n",
      "Epoch 12/250, Loss: 0.1499\n",
      "Epoch 13/250, Loss: 0.1390\n",
      "Epoch 14/250, Loss: 0.1286\n",
      "Epoch 15/250, Loss: 0.1211\n",
      "Epoch 16/250, Loss: 0.1121\n",
      "Epoch 17/250, Loss: 0.1041\n",
      "Epoch 18/250, Loss: 0.0936\n",
      "Epoch 19/250, Loss: 0.0874\n",
      "Epoch 20/250, Loss: 0.0651\n",
      "Epoch 21/250, Loss: 0.0586\n",
      "Epoch 22/250, Loss: 0.0545\n",
      "Epoch 23/250, Loss: 0.0499\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=350, Optimizer=SGD\n",
      "Epoch 1/350, Loss: 1.2789\n",
      "Epoch 2/350, Loss: 0.6754\n",
      "Epoch 3/350, Loss: 0.6154\n",
      "Epoch 4/350, Loss: 0.5785\n",
      "Epoch 5/350, Loss: 0.5481\n",
      "Epoch 6/350, Loss: 0.5266\n",
      "Epoch 7/350, Loss: 0.5031\n",
      "Epoch 8/350, Loss: 0.4865\n",
      "Epoch 9/350, Loss: 0.4688\n",
      "Epoch 10/350, Loss: 0.4579\n",
      "Epoch 11/350, Loss: 0.4437\n",
      "Epoch 12/350, Loss: 0.4327\n",
      "Epoch 13/350, Loss: 0.4211\n",
      "Epoch 14/350, Loss: 0.4139\n",
      "Epoch 15/350, Loss: 0.4066\n",
      "Epoch 16/350, Loss: 0.3980\n",
      "Epoch 17/350, Loss: 0.3912\n",
      "Epoch 18/350, Loss: 0.3835\n",
      "Epoch 19/350, Loss: 0.3777\n",
      "Epoch 20/350, Loss: 0.3726\n",
      "Epoch 21/350, Loss: 0.3667\n",
      "Epoch 22/350, Loss: 0.3612\n",
      "Epoch 23/350, Loss: 0.3566\n",
      "Epoch 24/350, Loss: 0.3515\n",
      "Epoch 25/350, Loss: 0.3479\n",
      "Epoch 26/350, Loss: 0.3423\n",
      "Epoch 27/350, Loss: 0.3389\n",
      "Epoch 28/350, Loss: 0.3348\n",
      "Epoch 29/350, Loss: 0.3297\n",
      "Epoch 30/350, Loss: 0.3272\n",
      "Epoch 31/350, Loss: 0.3237\n",
      "Epoch 32/350, Loss: 0.3203\n",
      "Epoch 33/350, Loss: 0.3173\n",
      "Epoch 34/350, Loss: 0.3145\n",
      "Epoch 35/350, Loss: 0.3105\n",
      "Epoch 36/350, Loss: 0.3076\n",
      "Epoch 37/350, Loss: 0.3058\n",
      "Epoch 38/350, Loss: 0.3022\n",
      "Epoch 39/350, Loss: 0.2992\n",
      "Epoch 40/350, Loss: 0.2960\n",
      "Epoch 41/350, Loss: 0.2950\n",
      "Epoch 42/350, Loss: 0.2924\n",
      "Epoch 43/350, Loss: 0.2891\n",
      "Epoch 44/350, Loss: 0.2888\n",
      "Epoch 45/350, Loss: 0.2841\n",
      "Epoch 46/350, Loss: 0.2830\n",
      "Epoch 47/350, Loss: 0.2812\n",
      "Epoch 48/350, Loss: 0.2789\n",
      "Epoch 49/350, Loss: 0.2767\n",
      "Epoch 50/350, Loss: 0.2751\n",
      "Epoch 51/350, Loss: 0.2729\n",
      "Epoch 52/350, Loss: 0.2709\n",
      "Epoch 53/350, Loss: 0.2688\n",
      "Epoch 54/350, Loss: 0.2676\n",
      "Epoch 55/350, Loss: 0.2660\n",
      "Epoch 56/350, Loss: 0.2621\n",
      "Epoch 57/350, Loss: 0.2619\n",
      "Epoch 58/350, Loss: 0.2598\n",
      "Epoch 59/350, Loss: 0.2582\n",
      "Epoch 60/350, Loss: 0.2568\n",
      "Epoch 61/350, Loss: 0.2552\n",
      "Epoch 62/350, Loss: 0.2535\n",
      "Epoch 63/350, Loss: 0.2512\n",
      "Epoch 64/350, Loss: 0.2504\n",
      "Epoch 65/350, Loss: 0.2492\n",
      "Epoch 66/350, Loss: 0.2483\n",
      "Epoch 67/350, Loss: 0.2457\n",
      "Epoch 68/350, Loss: 0.2432\n",
      "Epoch 69/350, Loss: 0.2429\n",
      "Epoch 70/350, Loss: 0.2421\n",
      "Epoch 71/350, Loss: 0.2399\n",
      "Epoch 72/350, Loss: 0.2383\n",
      "Epoch 73/350, Loss: 0.2372\n",
      "Epoch 74/350, Loss: 0.2358\n",
      "Epoch 75/350, Loss: 0.2342\n",
      "Epoch 76/350, Loss: 0.2322\n",
      "Epoch 77/350, Loss: 0.2295\n",
      "Epoch 78/350, Loss: 0.2309\n",
      "Epoch 79/350, Loss: 0.2283\n",
      "Epoch 80/350, Loss: 0.2270\n",
      "Epoch 81/350, Loss: 0.2265\n",
      "Epoch 82/350, Loss: 0.2251\n",
      "Epoch 83/350, Loss: 0.2229\n",
      "Epoch 84/350, Loss: 0.2219\n",
      "Epoch 85/350, Loss: 0.2210\n",
      "Epoch 86/350, Loss: 0.2202\n",
      "Epoch 87/350, Loss: 0.2194\n",
      "Epoch 88/350, Loss: 0.2178\n",
      "Epoch 89/350, Loss: 0.2169\n",
      "Epoch 90/350, Loss: 0.2153\n",
      "Epoch 91/350, Loss: 0.2055\n",
      "Epoch 92/350, Loss: 0.2044\n",
      "Epoch 93/350, Loss: 0.2032\n",
      "Epoch 94/350, Loss: 0.2028\n",
      "Epoch 95/350, Loss: 0.2023\n",
      "Epoch 96/350, Loss: 0.2013\n",
      "Epoch 97/350, Loss: 0.2007\n",
      "Epoch 98/350, Loss: 0.2005\n",
      "Epoch 99/350, Loss: 0.1996\n",
      "Epoch 100/350, Loss: 0.1996\n",
      "Epoch 101/350, Loss: 0.1984\n",
      "Epoch 102/350, Loss: 0.1983\n",
      "Epoch 103/350, Loss: 0.1931\n",
      "Epoch 104/350, Loss: 0.1926\n",
      "Epoch 105/350, Loss: 0.1921\n",
      "Epoch 106/350, Loss: 0.1920\n",
      "Epoch 107/350, Loss: 0.1912\n",
      "Epoch 108/350, Loss: 0.1913\n",
      "Epoch 109/350, Loss: 0.1908\n",
      "Epoch 110/350, Loss: 0.1905\n",
      "Epoch 111/350, Loss: 0.1881\n",
      "Epoch 112/350, Loss: 0.1875\n",
      "Epoch 113/350, Loss: 0.1874\n",
      "Epoch 114/350, Loss: 0.1874\n",
      "Epoch 115/350, Loss: 0.1872\n",
      "Epoch 116/350, Loss: 0.1872\n",
      "Epoch 117/350, Loss: 0.1867\n",
      "Epoch 118/350, Loss: 0.1867\n",
      "Epoch 119/350, Loss: 0.1865\n",
      "Epoch 120/350, Loss: 0.1862\n",
      "Epoch 121/350, Loss: 0.1861\n",
      "Epoch 122/350, Loss: 0.1860\n",
      "Epoch 123/350, Loss: 0.1857\n",
      "Epoch 124/350, Loss: 0.1844\n",
      "Epoch 125/350, Loss: 0.1844\n",
      "Epoch 126/350, Loss: 0.1841\n",
      "Epoch 127/350, Loss: 0.1842\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=350, Optimizer=RMSProp\n",
      "Epoch 1/350, Loss: 0.5439\n",
      "Epoch 2/350, Loss: 0.3466\n",
      "Epoch 3/350, Loss: 0.2971\n",
      "Epoch 4/350, Loss: 0.2644\n",
      "Epoch 5/350, Loss: 0.2414\n",
      "Epoch 6/350, Loss: 0.2232\n",
      "Epoch 7/350, Loss: 0.2078\n",
      "Epoch 8/350, Loss: 0.1942\n",
      "Epoch 9/350, Loss: 0.1806\n",
      "Epoch 10/350, Loss: 0.1701\n",
      "Epoch 11/350, Loss: 0.1591\n",
      "Epoch 12/350, Loss: 0.1497\n",
      "Epoch 13/350, Loss: 0.1402\n",
      "Epoch 14/350, Loss: 0.1306\n",
      "Epoch 15/350, Loss: 0.1227\n",
      "Epoch 16/350, Loss: 0.1155\n",
      "Epoch 17/350, Loss: 0.0919\n",
      "Epoch 18/350, Loss: 0.0856\n",
      "Epoch 19/350, Loss: 0.0798\n",
      "Epoch 20/350, Loss: 0.0752\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=3, Pooling=avg, Epochs=350, Optimizer=Adam\n",
      "Epoch 1/350, Loss: 0.5463\n",
      "Epoch 2/350, Loss: 0.3499\n",
      "Epoch 3/350, Loss: 0.2967\n",
      "Epoch 4/350, Loss: 0.2649\n",
      "Epoch 5/350, Loss: 0.2410\n",
      "Epoch 6/350, Loss: 0.2227\n",
      "Epoch 7/350, Loss: 0.2085\n",
      "Epoch 8/350, Loss: 0.1953\n",
      "Epoch 9/350, Loss: 0.1826\n",
      "Epoch 10/350, Loss: 0.1707\n",
      "Epoch 11/350, Loss: 0.1589\n",
      "Epoch 12/350, Loss: 0.1499\n",
      "Epoch 13/350, Loss: 0.1404\n",
      "Epoch 14/350, Loss: 0.1312\n",
      "Epoch 15/350, Loss: 0.1222\n",
      "Epoch 16/350, Loss: 0.0988\n",
      "Epoch 17/350, Loss: 0.0904\n",
      "Epoch 18/350, Loss: 0.0861\n",
      "Epoch 19/350, Loss: 0.0802\n",
      "Epoch 20/350, Loss: 0.0754\n",
      "Epoch 21/350, Loss: 0.0697\n",
      "Epoch 22/350, Loss: 0.0647\n",
      "Epoch 23/350, Loss: 0.0514\n",
      "Epoch 24/350, Loss: 0.0480\n",
      "Epoch 25/350, Loss: 0.0451\n",
      "Epoch 26/350, Loss: 0.0433\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=5, Optimizer=SGD\n",
      "Epoch 1/5, Loss: 1.0793\n",
      "Epoch 2/5, Loss: 0.6329\n",
      "Epoch 3/5, Loss: 0.5520\n",
      "Epoch 4/5, Loss: 0.4939\n",
      "Epoch 5/5, Loss: 0.4554\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=5, Optimizer=RMSProp\n",
      "Epoch 1/5, Loss: 0.4955\n",
      "Epoch 2/5, Loss: 0.2924\n",
      "Epoch 3/5, Loss: 0.2450\n",
      "Epoch 4/5, Loss: 0.2141\n",
      "Epoch 5/5, Loss: 0.1884\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=5, Optimizer=Adam\n",
      "Epoch 1/5, Loss: 0.4558\n",
      "Epoch 2/5, Loss: 0.2868\n",
      "Epoch 3/5, Loss: 0.2403\n",
      "Epoch 4/5, Loss: 0.2109\n",
      "Epoch 5/5, Loss: 0.1842\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=50, Optimizer=SGD\n",
      "Epoch 1/50, Loss: 1.1755\n",
      "Epoch 2/50, Loss: 0.6147\n",
      "Epoch 3/50, Loss: 0.5292\n",
      "Epoch 4/50, Loss: 0.4796\n",
      "Epoch 5/50, Loss: 0.4426\n",
      "Epoch 6/50, Loss: 0.4155\n",
      "Epoch 7/50, Loss: 0.3970\n",
      "Epoch 8/50, Loss: 0.3809\n",
      "Epoch 9/50, Loss: 0.3672\n",
      "Epoch 10/50, Loss: 0.3531\n",
      "Epoch 11/50, Loss: 0.3444\n",
      "Epoch 12/50, Loss: 0.3347\n",
      "Epoch 13/50, Loss: 0.3262\n",
      "Epoch 14/50, Loss: 0.3188\n",
      "Epoch 15/50, Loss: 0.3108\n",
      "Epoch 16/50, Loss: 0.3048\n",
      "Epoch 17/50, Loss: 0.2968\n",
      "Epoch 18/50, Loss: 0.2898\n",
      "Epoch 19/50, Loss: 0.2860\n",
      "Epoch 20/50, Loss: 0.2803\n",
      "Epoch 21/50, Loss: 0.2749\n",
      "Epoch 22/50, Loss: 0.2703\n",
      "Epoch 23/50, Loss: 0.2652\n",
      "Epoch 24/50, Loss: 0.2611\n",
      "Epoch 25/50, Loss: 0.2564\n",
      "Epoch 26/50, Loss: 0.2534\n",
      "Epoch 27/50, Loss: 0.2502\n",
      "Epoch 28/50, Loss: 0.2458\n",
      "Epoch 29/50, Loss: 0.2407\n",
      "Epoch 30/50, Loss: 0.2375\n",
      "Epoch 31/50, Loss: 0.2358\n",
      "Epoch 32/50, Loss: 0.2328\n",
      "Epoch 33/50, Loss: 0.2276\n",
      "Epoch 34/50, Loss: 0.2266\n",
      "Epoch 35/50, Loss: 0.2233\n",
      "Epoch 36/50, Loss: 0.2195\n",
      "Epoch 37/50, Loss: 0.2168\n",
      "Epoch 38/50, Loss: 0.2150\n",
      "Epoch 39/50, Loss: 0.2109\n",
      "Epoch 40/50, Loss: 0.2094\n",
      "Epoch 41/50, Loss: 0.2067\n",
      "Epoch 42/50, Loss: 0.2039\n",
      "Epoch 43/50, Loss: 0.2006\n",
      "Epoch 44/50, Loss: 0.1982\n",
      "Epoch 45/50, Loss: 0.1955\n",
      "Epoch 46/50, Loss: 0.1941\n",
      "Epoch 47/50, Loss: 0.1826\n",
      "Epoch 48/50, Loss: 0.1801\n",
      "Epoch 49/50, Loss: 0.1791\n",
      "Epoch 50/50, Loss: 0.1772\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=50, Optimizer=RMSProp\n",
      "Epoch 1/50, Loss: 0.5166\n",
      "Epoch 2/50, Loss: 0.3137\n",
      "Epoch 3/50, Loss: 0.2640\n",
      "Epoch 4/50, Loss: 0.2320\n",
      "Epoch 5/50, Loss: 0.2073\n",
      "Epoch 6/50, Loss: 0.1892\n",
      "Epoch 7/50, Loss: 0.1700\n",
      "Epoch 8/50, Loss: 0.1550\n",
      "Epoch 9/50, Loss: 0.1403\n",
      "Epoch 10/50, Loss: 0.1258\n",
      "Epoch 11/50, Loss: 0.1138\n",
      "Epoch 12/50, Loss: 0.1043\n",
      "Epoch 13/50, Loss: 0.0921\n",
      "Epoch 14/50, Loss: 0.0827\n",
      "Epoch 15/50, Loss: 0.0751\n",
      "Epoch 16/50, Loss: 0.0689\n",
      "Epoch 17/50, Loss: 0.0419\n",
      "Epoch 18/50, Loss: 0.0365\n",
      "Epoch 19/50, Loss: 0.0310\n",
      "Epoch 20/50, Loss: 0.0272\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=50, Optimizer=Adam\n",
      "Epoch 1/50, Loss: 0.4684\n",
      "Epoch 2/50, Loss: 0.2913\n",
      "Epoch 3/50, Loss: 0.2432\n",
      "Epoch 4/50, Loss: 0.2139\n",
      "Epoch 5/50, Loss: 0.1851\n",
      "Epoch 6/50, Loss: 0.1635\n",
      "Epoch 7/50, Loss: 0.1431\n",
      "Epoch 8/50, Loss: 0.1258\n",
      "Epoch 9/50, Loss: 0.1101\n",
      "Epoch 10/50, Loss: 0.0935\n",
      "Epoch 11/50, Loss: 0.0812\n",
      "Epoch 12/50, Loss: 0.0459\n",
      "Epoch 13/50, Loss: 0.0359\n",
      "Epoch 14/50, Loss: 0.0296\n",
      "Epoch 15/50, Loss: 0.0266\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=100, Optimizer=SGD\n",
      "Epoch 1/100, Loss: 1.0718\n",
      "Epoch 2/100, Loss: 0.6279\n",
      "Epoch 3/100, Loss: 0.5485\n",
      "Epoch 4/100, Loss: 0.4927\n",
      "Epoch 5/100, Loss: 0.4544\n",
      "Epoch 6/100, Loss: 0.4268\n",
      "Epoch 7/100, Loss: 0.4032\n",
      "Epoch 8/100, Loss: 0.3873\n",
      "Epoch 9/100, Loss: 0.3714\n",
      "Epoch 10/100, Loss: 0.3570\n",
      "Epoch 11/100, Loss: 0.3467\n",
      "Epoch 12/100, Loss: 0.3388\n",
      "Epoch 13/100, Loss: 0.3298\n",
      "Epoch 14/100, Loss: 0.3183\n",
      "Epoch 15/100, Loss: 0.3122\n",
      "Epoch 16/100, Loss: 0.3040\n",
      "Epoch 17/100, Loss: 0.2974\n",
      "Epoch 18/100, Loss: 0.2918\n",
      "Epoch 19/100, Loss: 0.2869\n",
      "Epoch 20/100, Loss: 0.2812\n",
      "Epoch 21/100, Loss: 0.2765\n",
      "Epoch 22/100, Loss: 0.2706\n",
      "Epoch 23/100, Loss: 0.2657\n",
      "Epoch 24/100, Loss: 0.2621\n",
      "Epoch 25/100, Loss: 0.2578\n",
      "Epoch 26/100, Loss: 0.2543\n",
      "Epoch 27/100, Loss: 0.2510\n",
      "Epoch 28/100, Loss: 0.2471\n",
      "Epoch 29/100, Loss: 0.2437\n",
      "Epoch 30/100, Loss: 0.2409\n",
      "Epoch 31/100, Loss: 0.2368\n",
      "Epoch 32/100, Loss: 0.2335\n",
      "Epoch 33/100, Loss: 0.2312\n",
      "Epoch 34/100, Loss: 0.2272\n",
      "Epoch 35/100, Loss: 0.2247\n",
      "Epoch 36/100, Loss: 0.2223\n",
      "Epoch 37/100, Loss: 0.2190\n",
      "Epoch 38/100, Loss: 0.2172\n",
      "Epoch 39/100, Loss: 0.2132\n",
      "Epoch 40/100, Loss: 0.2108\n",
      "Epoch 41/100, Loss: 0.2090\n",
      "Epoch 42/100, Loss: 0.2069\n",
      "Epoch 43/100, Loss: 0.2034\n",
      "Epoch 44/100, Loss: 0.2010\n",
      "Epoch 45/100, Loss: 0.1996\n",
      "Epoch 46/100, Loss: 0.1967\n",
      "Epoch 47/100, Loss: 0.1942\n",
      "Epoch 48/100, Loss: 0.1908\n",
      "Epoch 49/100, Loss: 0.1896\n",
      "Epoch 50/100, Loss: 0.1870\n",
      "Epoch 51/100, Loss: 0.1852\n",
      "Epoch 52/100, Loss: 0.1835\n",
      "Epoch 53/100, Loss: 0.1825\n",
      "Epoch 54/100, Loss: 0.1778\n",
      "Epoch 55/100, Loss: 0.1765\n",
      "Epoch 56/100, Loss: 0.1737\n",
      "Epoch 57/100, Loss: 0.1720\n",
      "Epoch 58/100, Loss: 0.1709\n",
      "Epoch 59/100, Loss: 0.1671\n",
      "Epoch 60/100, Loss: 0.1661\n",
      "Epoch 61/100, Loss: 0.1643\n",
      "Epoch 62/100, Loss: 0.1626\n",
      "Epoch 63/100, Loss: 0.1590\n",
      "Epoch 64/100, Loss: 0.1593\n",
      "Epoch 65/100, Loss: 0.1563\n",
      "Epoch 66/100, Loss: 0.1557\n",
      "Epoch 67/100, Loss: 0.1537\n",
      "Epoch 68/100, Loss: 0.1508\n",
      "Epoch 69/100, Loss: 0.1497\n",
      "Epoch 70/100, Loss: 0.1475\n",
      "Epoch 71/100, Loss: 0.1449\n",
      "Epoch 72/100, Loss: 0.1326\n",
      "Epoch 73/100, Loss: 0.1314\n",
      "Epoch 74/100, Loss: 0.1296\n",
      "Epoch 75/100, Loss: 0.1284\n",
      "Epoch 76/100, Loss: 0.1277\n",
      "Epoch 77/100, Loss: 0.1268\n",
      "Epoch 78/100, Loss: 0.1263\n",
      "Epoch 79/100, Loss: 0.1244\n",
      "Epoch 80/100, Loss: 0.1232\n",
      "Epoch 81/100, Loss: 0.1222\n",
      "Epoch 82/100, Loss: 0.1211\n",
      "Epoch 83/100, Loss: 0.1154\n",
      "Epoch 84/100, Loss: 0.1146\n",
      "Epoch 85/100, Loss: 0.1143\n",
      "Epoch 86/100, Loss: 0.1133\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=100, Optimizer=RMSProp\n",
      "Epoch 1/100, Loss: 0.5101\n",
      "Epoch 2/100, Loss: 0.3019\n",
      "Epoch 3/100, Loss: 0.2538\n",
      "Epoch 4/100, Loss: 0.2207\n",
      "Epoch 5/100, Loss: 0.1955\n",
      "Epoch 6/100, Loss: 0.1752\n",
      "Epoch 7/100, Loss: 0.1569\n",
      "Epoch 8/100, Loss: 0.1401\n",
      "Epoch 9/100, Loss: 0.1240\n",
      "Epoch 10/100, Loss: 0.1108\n",
      "Epoch 11/100, Loss: 0.0988\n",
      "Epoch 12/100, Loss: 0.0877\n",
      "Epoch 13/100, Loss: 0.0764\n",
      "Epoch 14/100, Loss: 0.0489\n",
      "Epoch 15/100, Loss: 0.0404\n",
      "Epoch 16/100, Loss: 0.0346\n",
      "Epoch 17/100, Loss: 0.0297\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=100, Optimizer=Adam\n",
      "Epoch 1/100, Loss: 0.4772\n",
      "Epoch 2/100, Loss: 0.2952\n",
      "Epoch 3/100, Loss: 0.2459\n",
      "Epoch 4/100, Loss: 0.2135\n",
      "Epoch 5/100, Loss: 0.1867\n",
      "Epoch 6/100, Loss: 0.1647\n",
      "Epoch 7/100, Loss: 0.1428\n",
      "Epoch 8/100, Loss: 0.1249\n",
      "Epoch 9/100, Loss: 0.1069\n",
      "Epoch 10/100, Loss: 0.0913\n",
      "Epoch 11/100, Loss: 0.0755\n",
      "Epoch 12/100, Loss: 0.0668\n",
      "Epoch 13/100, Loss: 0.0559\n",
      "Epoch 14/100, Loss: 0.0287\n",
      "Epoch 15/100, Loss: 0.0205\n",
      "Epoch 16/100, Loss: 0.0161\n",
      "Epoch 17/100, Loss: 0.0151\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=250, Optimizer=SGD\n",
      "Epoch 1/250, Loss: 1.1134\n",
      "Epoch 2/250, Loss: 0.6055\n",
      "Epoch 3/250, Loss: 0.5251\n",
      "Epoch 4/250, Loss: 0.4756\n",
      "Epoch 5/250, Loss: 0.4393\n",
      "Epoch 6/250, Loss: 0.4162\n",
      "Epoch 7/250, Loss: 0.3961\n",
      "Epoch 8/250, Loss: 0.3803\n",
      "Epoch 9/250, Loss: 0.3655\n",
      "Epoch 10/250, Loss: 0.3560\n",
      "Epoch 11/250, Loss: 0.3439\n",
      "Epoch 12/250, Loss: 0.3357\n",
      "Epoch 13/250, Loss: 0.3266\n",
      "Epoch 14/250, Loss: 0.3212\n",
      "Epoch 15/250, Loss: 0.3130\n",
      "Epoch 16/250, Loss: 0.3057\n",
      "Epoch 17/250, Loss: 0.2998\n",
      "Epoch 18/250, Loss: 0.2929\n",
      "Epoch 19/250, Loss: 0.2886\n",
      "Epoch 20/250, Loss: 0.2833\n",
      "Epoch 21/250, Loss: 0.2781\n",
      "Epoch 22/250, Loss: 0.2732\n",
      "Epoch 23/250, Loss: 0.2676\n",
      "Epoch 24/250, Loss: 0.2648\n",
      "Epoch 25/250, Loss: 0.2615\n",
      "Epoch 26/250, Loss: 0.2576\n",
      "Epoch 27/250, Loss: 0.2543\n",
      "Epoch 28/250, Loss: 0.2493\n",
      "Epoch 29/250, Loss: 0.2463\n",
      "Epoch 30/250, Loss: 0.2430\n",
      "Epoch 31/250, Loss: 0.2393\n",
      "Epoch 32/250, Loss: 0.2368\n",
      "Epoch 33/250, Loss: 0.2331\n",
      "Epoch 34/250, Loss: 0.2304\n",
      "Epoch 35/250, Loss: 0.2285\n",
      "Epoch 36/250, Loss: 0.2253\n",
      "Epoch 37/250, Loss: 0.2229\n",
      "Epoch 38/250, Loss: 0.2196\n",
      "Epoch 39/250, Loss: 0.2165\n",
      "Epoch 40/250, Loss: 0.2147\n",
      "Epoch 41/250, Loss: 0.2118\n",
      "Epoch 42/250, Loss: 0.2088\n",
      "Epoch 43/250, Loss: 0.2062\n",
      "Epoch 44/250, Loss: 0.2037\n",
      "Epoch 45/250, Loss: 0.2014\n",
      "Epoch 46/250, Loss: 0.2003\n",
      "Epoch 47/250, Loss: 0.1969\n",
      "Epoch 48/250, Loss: 0.1952\n",
      "Epoch 49/250, Loss: 0.1923\n",
      "Epoch 50/250, Loss: 0.1907\n",
      "Epoch 51/250, Loss: 0.1876\n",
      "Epoch 52/250, Loss: 0.1854\n",
      "Epoch 53/250, Loss: 0.1834\n",
      "Epoch 54/250, Loss: 0.1815\n",
      "Epoch 55/250, Loss: 0.1792\n",
      "Epoch 56/250, Loss: 0.1778\n",
      "Epoch 57/250, Loss: 0.1746\n",
      "Epoch 58/250, Loss: 0.1728\n",
      "Epoch 59/250, Loss: 0.1712\n",
      "Epoch 60/250, Loss: 0.1697\n",
      "Epoch 61/250, Loss: 0.1665\n",
      "Epoch 62/250, Loss: 0.1653\n",
      "Epoch 63/250, Loss: 0.1621\n",
      "Epoch 64/250, Loss: 0.1624\n",
      "Epoch 65/250, Loss: 0.1604\n",
      "Epoch 66/250, Loss: 0.1567\n",
      "Epoch 67/250, Loss: 0.1555\n",
      "Epoch 68/250, Loss: 0.1537\n",
      "Epoch 69/250, Loss: 0.1523\n",
      "Epoch 70/250, Loss: 0.1391\n",
      "Epoch 71/250, Loss: 0.1373\n",
      "Epoch 72/250, Loss: 0.1369\n",
      "Epoch 73/250, Loss: 0.1354\n",
      "Epoch 74/250, Loss: 0.1344\n",
      "Epoch 75/250, Loss: 0.1330\n",
      "Epoch 76/250, Loss: 0.1328\n",
      "Epoch 77/250, Loss: 0.1308\n",
      "Epoch 78/250, Loss: 0.1255\n",
      "Epoch 79/250, Loss: 0.1247\n",
      "Epoch 80/250, Loss: 0.1242\n",
      "Epoch 81/250, Loss: 0.1232\n",
      "Epoch 82/250, Loss: 0.1229\n",
      "Epoch 83/250, Loss: 0.1223\n",
      "Epoch 84/250, Loss: 0.1215\n",
      "Epoch 85/250, Loss: 0.1208\n",
      "Epoch 86/250, Loss: 0.1182\n",
      "Epoch 87/250, Loss: 0.1179\n",
      "Epoch 88/250, Loss: 0.1176\n",
      "Epoch 89/250, Loss: 0.1174\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=250, Optimizer=RMSProp\n",
      "Epoch 1/250, Loss: 0.5135\n",
      "Epoch 2/250, Loss: 0.3045\n",
      "Epoch 3/250, Loss: 0.2547\n",
      "Epoch 4/250, Loss: 0.2200\n",
      "Epoch 5/250, Loss: 0.1960\n",
      "Epoch 6/250, Loss: 0.1752\n",
      "Epoch 7/250, Loss: 0.1560\n",
      "Epoch 8/250, Loss: 0.1392\n",
      "Epoch 9/250, Loss: 0.1237\n",
      "Epoch 10/250, Loss: 0.1090\n",
      "Epoch 11/250, Loss: 0.0955\n",
      "Epoch 12/250, Loss: 0.0652\n",
      "Epoch 13/250, Loss: 0.0547\n",
      "Epoch 14/250, Loss: 0.0480\n",
      "Epoch 15/250, Loss: 0.0412\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=250, Optimizer=Adam\n",
      "Epoch 1/250, Loss: 0.4532\n",
      "Epoch 2/250, Loss: 0.2874\n",
      "Epoch 3/250, Loss: 0.2387\n",
      "Epoch 4/250, Loss: 0.2088\n",
      "Epoch 5/250, Loss: 0.1837\n",
      "Epoch 6/250, Loss: 0.1601\n",
      "Epoch 7/250, Loss: 0.1384\n",
      "Epoch 8/250, Loss: 0.1216\n",
      "Epoch 9/250, Loss: 0.1054\n",
      "Epoch 10/250, Loss: 0.0902\n",
      "Epoch 11/250, Loss: 0.0761\n",
      "Epoch 12/250, Loss: 0.0438\n",
      "Epoch 13/250, Loss: 0.0340\n",
      "Epoch 14/250, Loss: 0.0289\n",
      "Epoch 15/250, Loss: 0.0236\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=350, Optimizer=SGD\n",
      "Epoch 1/350, Loss: 1.1412\n",
      "Epoch 2/350, Loss: 0.5893\n",
      "Epoch 3/350, Loss: 0.5139\n",
      "Epoch 4/350, Loss: 0.4658\n",
      "Epoch 5/350, Loss: 0.4342\n",
      "Epoch 6/350, Loss: 0.4117\n",
      "Epoch 7/350, Loss: 0.3916\n",
      "Epoch 8/350, Loss: 0.3756\n",
      "Epoch 9/350, Loss: 0.3625\n",
      "Epoch 10/350, Loss: 0.3536\n",
      "Epoch 11/350, Loss: 0.3421\n",
      "Epoch 12/350, Loss: 0.3340\n",
      "Epoch 13/350, Loss: 0.3241\n",
      "Epoch 14/350, Loss: 0.3188\n",
      "Epoch 15/350, Loss: 0.3094\n",
      "Epoch 16/350, Loss: 0.3037\n",
      "Epoch 17/350, Loss: 0.2977\n",
      "Epoch 18/350, Loss: 0.2915\n",
      "Epoch 19/350, Loss: 0.2853\n",
      "Epoch 20/350, Loss: 0.2805\n",
      "Epoch 21/350, Loss: 0.2756\n",
      "Epoch 22/350, Loss: 0.2700\n",
      "Epoch 23/350, Loss: 0.2667\n",
      "Epoch 24/350, Loss: 0.2617\n",
      "Epoch 25/350, Loss: 0.2576\n",
      "Epoch 26/350, Loss: 0.2539\n",
      "Epoch 27/350, Loss: 0.2502\n",
      "Epoch 28/350, Loss: 0.2463\n",
      "Epoch 29/350, Loss: 0.2426\n",
      "Epoch 30/350, Loss: 0.2395\n",
      "Epoch 31/350, Loss: 0.2366\n",
      "Epoch 32/350, Loss: 0.2316\n",
      "Epoch 33/350, Loss: 0.2292\n",
      "Epoch 34/350, Loss: 0.2270\n",
      "Epoch 35/350, Loss: 0.2243\n",
      "Epoch 36/350, Loss: 0.2203\n",
      "Epoch 37/350, Loss: 0.2192\n",
      "Epoch 38/350, Loss: 0.2155\n",
      "Epoch 39/350, Loss: 0.2049\n",
      "Epoch 40/350, Loss: 0.2027\n",
      "Epoch 41/350, Loss: 0.2006\n",
      "Epoch 42/350, Loss: 0.1998\n",
      "Epoch 43/350, Loss: 0.1973\n",
      "Epoch 44/350, Loss: 0.1969\n",
      "Epoch 45/350, Loss: 0.1949\n",
      "Epoch 46/350, Loss: 0.1937\n",
      "Epoch 47/350, Loss: 0.1918\n",
      "Epoch 48/350, Loss: 0.1905\n",
      "Epoch 49/350, Loss: 0.1891\n",
      "Epoch 50/350, Loss: 0.1883\n",
      "Epoch 51/350, Loss: 0.1863\n",
      "Epoch 52/350, Loss: 0.1860\n",
      "Epoch 53/350, Loss: 0.1842\n",
      "Epoch 54/350, Loss: 0.1824\n",
      "Epoch 55/350, Loss: 0.1818\n",
      "Epoch 56/350, Loss: 0.1800\n",
      "Epoch 57/350, Loss: 0.1789\n",
      "Epoch 58/350, Loss: 0.1780\n",
      "Epoch 59/350, Loss: 0.1761\n",
      "Epoch 60/350, Loss: 0.1749\n",
      "Epoch 61/350, Loss: 0.1743\n",
      "Epoch 62/350, Loss: 0.1676\n",
      "Epoch 63/350, Loss: 0.1667\n",
      "Epoch 64/350, Loss: 0.1659\n",
      "Epoch 65/350, Loss: 0.1652\n",
      "Epoch 66/350, Loss: 0.1646\n",
      "Epoch 67/350, Loss: 0.1641\n",
      "Epoch 68/350, Loss: 0.1629\n",
      "Epoch 69/350, Loss: 0.1625\n",
      "Epoch 70/350, Loss: 0.1618\n",
      "Epoch 71/350, Loss: 0.1611\n",
      "Epoch 72/350, Loss: 0.1606\n",
      "Epoch 73/350, Loss: 0.1599\n",
      "Epoch 74/350, Loss: 0.1593\n",
      "Epoch 75/350, Loss: 0.1561\n",
      "Epoch 76/350, Loss: 0.1555\n",
      "Epoch 77/350, Loss: 0.1552\n",
      "Epoch 78/350, Loss: 0.1547\n",
      "Epoch 79/350, Loss: 0.1545\n",
      "Epoch 80/350, Loss: 0.1543\n",
      "Epoch 81/350, Loss: 0.1536\n",
      "Epoch 82/350, Loss: 0.1533\n",
      "Epoch 83/350, Loss: 0.1530\n",
      "Epoch 84/350, Loss: 0.1527\n",
      "Epoch 85/350, Loss: 0.1510\n",
      "Epoch 86/350, Loss: 0.1510\n",
      "Epoch 87/350, Loss: 0.1507\n",
      "Epoch 88/350, Loss: 0.1505\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=350, Optimizer=RMSProp\n",
      "Epoch 1/350, Loss: 0.4905\n",
      "Epoch 2/350, Loss: 0.3059\n",
      "Epoch 3/350, Loss: 0.2598\n",
      "Epoch 4/350, Loss: 0.2287\n",
      "Epoch 5/350, Loss: 0.2064\n",
      "Epoch 6/350, Loss: 0.1861\n",
      "Epoch 7/350, Loss: 0.1687\n",
      "Epoch 8/350, Loss: 0.1530\n",
      "Epoch 9/350, Loss: 0.1386\n",
      "Epoch 10/350, Loss: 0.1250\n",
      "Epoch 11/350, Loss: 0.1146\n",
      "Epoch 12/350, Loss: 0.1036\n",
      "Epoch 13/350, Loss: 0.0928\n",
      "Epoch 14/350, Loss: 0.0639\n",
      "Epoch 15/350, Loss: 0.0544\n",
      "Epoch 16/350, Loss: 0.0490\n",
      "Epoch 17/350, Loss: 0.0430\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=max, Epochs=350, Optimizer=Adam\n",
      "Epoch 1/350, Loss: 0.4707\n",
      "Epoch 2/350, Loss: 0.2933\n",
      "Epoch 3/350, Loss: 0.2480\n",
      "Epoch 4/350, Loss: 0.2153\n",
      "Epoch 5/350, Loss: 0.1900\n",
      "Epoch 6/350, Loss: 0.1668\n",
      "Epoch 7/350, Loss: 0.1464\n",
      "Epoch 8/350, Loss: 0.1272\n",
      "Epoch 9/350, Loss: 0.1099\n",
      "Epoch 10/350, Loss: 0.0938\n",
      "Epoch 11/350, Loss: 0.0816\n",
      "Epoch 12/350, Loss: 0.0696\n",
      "Epoch 13/350, Loss: 0.0373\n",
      "Epoch 14/350, Loss: 0.0282\n",
      "Epoch 15/350, Loss: 0.0235\n",
      "Epoch 16/350, Loss: 0.0194\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=5, Optimizer=SGD\n",
      "Epoch 1/5, Loss: 1.3489\n",
      "Epoch 2/5, Loss: 0.6973\n",
      "Epoch 3/5, Loss: 0.6218\n",
      "Epoch 4/5, Loss: 0.5694\n",
      "Epoch 5/5, Loss: 0.5344\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=5, Optimizer=RMSProp\n",
      "Epoch 1/5, Loss: 0.5685\n",
      "Epoch 2/5, Loss: 0.3475\n",
      "Epoch 3/5, Loss: 0.2919\n",
      "Epoch 4/5, Loss: 0.2578\n",
      "Epoch 5/5, Loss: 0.2321\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=5, Optimizer=Adam\n",
      "Epoch 1/5, Loss: 0.5141\n",
      "Epoch 2/5, Loss: 0.3313\n",
      "Epoch 3/5, Loss: 0.2803\n",
      "Epoch 4/5, Loss: 0.2482\n",
      "Epoch 5/5, Loss: 0.2269\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=50, Optimizer=SGD\n",
      "Epoch 1/50, Loss: 1.2525\n",
      "Epoch 2/50, Loss: 0.6998\n",
      "Epoch 3/50, Loss: 0.6252\n",
      "Epoch 4/50, Loss: 0.5813\n",
      "Epoch 5/50, Loss: 0.5434\n",
      "Epoch 6/50, Loss: 0.5134\n",
      "Epoch 7/50, Loss: 0.4886\n",
      "Epoch 8/50, Loss: 0.4673\n",
      "Epoch 9/50, Loss: 0.4505\n",
      "Epoch 10/50, Loss: 0.4378\n",
      "Epoch 11/50, Loss: 0.4248\n",
      "Epoch 12/50, Loss: 0.4123\n",
      "Epoch 13/50, Loss: 0.4027\n",
      "Epoch 14/50, Loss: 0.3926\n",
      "Epoch 15/50, Loss: 0.3862\n",
      "Epoch 16/50, Loss: 0.3789\n",
      "Epoch 17/50, Loss: 0.3726\n",
      "Epoch 18/50, Loss: 0.3652\n",
      "Epoch 19/50, Loss: 0.3589\n",
      "Epoch 20/50, Loss: 0.3547\n",
      "Epoch 21/50, Loss: 0.3482\n",
      "Epoch 22/50, Loss: 0.3446\n",
      "Epoch 23/50, Loss: 0.3405\n",
      "Epoch 24/50, Loss: 0.3347\n",
      "Epoch 25/50, Loss: 0.3299\n",
      "Epoch 26/50, Loss: 0.3278\n",
      "Epoch 27/50, Loss: 0.3229\n",
      "Epoch 28/50, Loss: 0.3189\n",
      "Epoch 29/50, Loss: 0.3145\n",
      "Epoch 30/50, Loss: 0.3102\n",
      "Epoch 31/50, Loss: 0.3086\n",
      "Epoch 32/50, Loss: 0.3042\n",
      "Epoch 33/50, Loss: 0.3016\n",
      "Epoch 34/50, Loss: 0.2996\n",
      "Epoch 35/50, Loss: 0.2967\n",
      "Epoch 36/50, Loss: 0.2937\n",
      "Epoch 37/50, Loss: 0.2905\n",
      "Epoch 38/50, Loss: 0.2874\n",
      "Epoch 39/50, Loss: 0.2853\n",
      "Epoch 40/50, Loss: 0.2824\n",
      "Epoch 41/50, Loss: 0.2799\n",
      "Epoch 42/50, Loss: 0.2775\n",
      "Epoch 43/50, Loss: 0.2755\n",
      "Epoch 44/50, Loss: 0.2741\n",
      "Epoch 45/50, Loss: 0.2723\n",
      "Epoch 46/50, Loss: 0.2698\n",
      "Epoch 47/50, Loss: 0.2673\n",
      "Epoch 48/50, Loss: 0.2658\n",
      "Epoch 49/50, Loss: 0.2620\n",
      "Epoch 50/50, Loss: 0.2620\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=50, Optimizer=RMSProp\n",
      "Epoch 1/50, Loss: 0.5393\n",
      "Epoch 2/50, Loss: 0.3366\n",
      "Epoch 3/50, Loss: 0.2850\n",
      "Epoch 4/50, Loss: 0.2518\n",
      "Epoch 5/50, Loss: 0.2274\n",
      "Epoch 6/50, Loss: 0.2078\n",
      "Epoch 7/50, Loss: 0.1911\n",
      "Epoch 8/50, Loss: 0.1753\n",
      "Epoch 9/50, Loss: 0.1628\n",
      "Epoch 10/50, Loss: 0.1493\n",
      "Epoch 11/50, Loss: 0.1367\n",
      "Epoch 12/50, Loss: 0.1258\n",
      "Epoch 13/50, Loss: 0.1160\n",
      "Epoch 14/50, Loss: 0.1064\n",
      "Epoch 15/50, Loss: 0.0952\n",
      "Epoch 16/50, Loss: 0.0871\n",
      "Epoch 17/50, Loss: 0.0615\n",
      "Epoch 18/50, Loss: 0.0547\n",
      "Epoch 19/50, Loss: 0.0490\n",
      "Epoch 20/50, Loss: 0.0449\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=50, Optimizer=Adam\n",
      "Epoch 1/50, Loss: 0.5340\n",
      "Epoch 2/50, Loss: 0.3391\n",
      "Epoch 3/50, Loss: 0.2849\n",
      "Epoch 4/50, Loss: 0.2547\n",
      "Epoch 5/50, Loss: 0.2325\n",
      "Epoch 6/50, Loss: 0.2130\n",
      "Epoch 7/50, Loss: 0.1991\n",
      "Epoch 8/50, Loss: 0.1830\n",
      "Epoch 9/50, Loss: 0.1710\n",
      "Epoch 10/50, Loss: 0.1589\n",
      "Epoch 11/50, Loss: 0.1468\n",
      "Epoch 12/50, Loss: 0.1352\n",
      "Epoch 13/50, Loss: 0.1242\n",
      "Epoch 14/50, Loss: 0.1123\n",
      "Epoch 15/50, Loss: 0.1040\n",
      "Epoch 16/50, Loss: 0.0937\n",
      "Epoch 17/50, Loss: 0.0870\n",
      "Epoch 18/50, Loss: 0.0592\n",
      "Epoch 19/50, Loss: 0.0507\n",
      "Epoch 20/50, Loss: 0.0466\n",
      "Epoch 21/50, Loss: 0.0418\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=100, Optimizer=SGD\n",
      "Epoch 1/100, Loss: 1.3209\n",
      "Epoch 2/100, Loss: 0.6996\n",
      "Epoch 3/100, Loss: 0.6218\n",
      "Epoch 4/100, Loss: 0.5772\n",
      "Epoch 5/100, Loss: 0.5404\n",
      "Epoch 6/100, Loss: 0.5090\n",
      "Epoch 7/100, Loss: 0.4851\n",
      "Epoch 8/100, Loss: 0.4649\n",
      "Epoch 9/100, Loss: 0.4474\n",
      "Epoch 10/100, Loss: 0.4330\n",
      "Epoch 11/100, Loss: 0.4200\n",
      "Epoch 12/100, Loss: 0.4090\n",
      "Epoch 13/100, Loss: 0.4007\n",
      "Epoch 14/100, Loss: 0.3917\n",
      "Epoch 15/100, Loss: 0.3836\n",
      "Epoch 16/100, Loss: 0.3771\n",
      "Epoch 17/100, Loss: 0.3714\n",
      "Epoch 18/100, Loss: 0.3653\n",
      "Epoch 19/100, Loss: 0.3579\n",
      "Epoch 20/100, Loss: 0.3539\n",
      "Epoch 21/100, Loss: 0.3468\n",
      "Epoch 22/100, Loss: 0.3431\n",
      "Epoch 23/100, Loss: 0.3367\n",
      "Epoch 24/100, Loss: 0.3331\n",
      "Epoch 25/100, Loss: 0.3283\n",
      "Epoch 26/100, Loss: 0.3241\n",
      "Epoch 27/100, Loss: 0.3201\n",
      "Epoch 28/100, Loss: 0.3147\n",
      "Epoch 29/100, Loss: 0.3125\n",
      "Epoch 30/100, Loss: 0.3095\n",
      "Epoch 31/100, Loss: 0.3050\n",
      "Epoch 32/100, Loss: 0.3019\n",
      "Epoch 33/100, Loss: 0.2983\n",
      "Epoch 34/100, Loss: 0.2959\n",
      "Epoch 35/100, Loss: 0.2935\n",
      "Epoch 36/100, Loss: 0.2889\n",
      "Epoch 37/100, Loss: 0.2851\n",
      "Epoch 38/100, Loss: 0.2825\n",
      "Epoch 39/100, Loss: 0.2811\n",
      "Epoch 40/100, Loss: 0.2783\n",
      "Epoch 41/100, Loss: 0.2760\n",
      "Epoch 42/100, Loss: 0.2732\n",
      "Epoch 43/100, Loss: 0.2706\n",
      "Epoch 44/100, Loss: 0.2677\n",
      "Epoch 45/100, Loss: 0.2658\n",
      "Epoch 46/100, Loss: 0.2646\n",
      "Epoch 47/100, Loss: 0.2620\n",
      "Epoch 48/100, Loss: 0.2606\n",
      "Epoch 49/100, Loss: 0.2575\n",
      "Epoch 50/100, Loss: 0.2555\n",
      "Epoch 51/100, Loss: 0.2532\n",
      "Epoch 52/100, Loss: 0.2527\n",
      "Epoch 53/100, Loss: 0.2493\n",
      "Epoch 54/100, Loss: 0.2482\n",
      "Epoch 55/100, Loss: 0.2457\n",
      "Epoch 56/100, Loss: 0.2441\n",
      "Epoch 57/100, Loss: 0.2416\n",
      "Epoch 58/100, Loss: 0.2397\n",
      "Epoch 59/100, Loss: 0.2386\n",
      "Epoch 60/100, Loss: 0.2374\n",
      "Epoch 61/100, Loss: 0.2358\n",
      "Epoch 62/100, Loss: 0.2343\n",
      "Epoch 63/100, Loss: 0.2324\n",
      "Epoch 64/100, Loss: 0.2306\n",
      "Epoch 65/100, Loss: 0.2289\n",
      "Epoch 66/100, Loss: 0.2287\n",
      "Epoch 67/100, Loss: 0.2254\n",
      "Epoch 68/100, Loss: 0.2243\n",
      "Epoch 69/100, Loss: 0.2226\n",
      "Epoch 70/100, Loss: 0.2217\n",
      "Epoch 71/100, Loss: 0.2198\n",
      "Epoch 72/100, Loss: 0.2093\n",
      "Epoch 73/100, Loss: 0.2077\n",
      "Epoch 74/100, Loss: 0.2071\n",
      "Epoch 75/100, Loss: 0.2066\n",
      "Epoch 76/100, Loss: 0.2058\n",
      "Epoch 77/100, Loss: 0.2049\n",
      "Epoch 78/100, Loss: 0.2043\n",
      "Epoch 79/100, Loss: 0.2034\n",
      "Epoch 80/100, Loss: 0.2026\n",
      "Epoch 81/100, Loss: 0.2013\n",
      "Epoch 82/100, Loss: 0.2009\n",
      "Epoch 83/100, Loss: 0.2000\n",
      "Epoch 84/100, Loss: 0.1999\n",
      "Epoch 85/100, Loss: 0.1986\n",
      "Epoch 86/100, Loss: 0.1983\n",
      "Epoch 87/100, Loss: 0.1972\n",
      "Epoch 88/100, Loss: 0.1967\n",
      "Epoch 89/100, Loss: 0.1961\n",
      "Epoch 90/100, Loss: 0.1951\n",
      "Epoch 91/100, Loss: 0.1944\n",
      "Epoch 92/100, Loss: 0.1942\n",
      "Epoch 93/100, Loss: 0.1930\n",
      "Epoch 94/100, Loss: 0.1924\n",
      "Epoch 95/100, Loss: 0.1922\n",
      "Epoch 96/100, Loss: 0.1909\n",
      "Epoch 97/100, Loss: 0.1911\n",
      "Epoch 98/100, Loss: 0.1905\n",
      "Epoch 99/100, Loss: 0.1891\n",
      "Epoch 100/100, Loss: 0.1889\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=100, Optimizer=RMSProp\n",
      "Epoch 1/100, Loss: 0.5004\n",
      "Epoch 2/100, Loss: 0.3207\n",
      "Epoch 3/100, Loss: 0.2731\n",
      "Epoch 4/100, Loss: 0.2426\n",
      "Epoch 5/100, Loss: 0.2203\n",
      "Epoch 6/100, Loss: 0.2014\n",
      "Epoch 7/100, Loss: 0.1867\n",
      "Epoch 8/100, Loss: 0.1711\n",
      "Epoch 9/100, Loss: 0.1573\n",
      "Epoch 10/100, Loss: 0.1450\n",
      "Epoch 11/100, Loss: 0.1333\n",
      "Epoch 12/100, Loss: 0.1205\n",
      "Epoch 13/100, Loss: 0.1121\n",
      "Epoch 14/100, Loss: 0.1021\n",
      "Epoch 15/100, Loss: 0.0747\n",
      "Epoch 16/100, Loss: 0.0659\n",
      "Epoch 17/100, Loss: 0.0603\n",
      "Epoch 18/100, Loss: 0.0548\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=100, Optimizer=Adam\n",
      "Epoch 1/100, Loss: 0.5224\n",
      "Epoch 2/100, Loss: 0.3328\n",
      "Epoch 3/100, Loss: 0.2830\n",
      "Epoch 4/100, Loss: 0.2528\n",
      "Epoch 5/100, Loss: 0.2285\n",
      "Epoch 6/100, Loss: 0.2080\n",
      "Epoch 7/100, Loss: 0.1926\n",
      "Epoch 8/100, Loss: 0.1749\n",
      "Epoch 9/100, Loss: 0.1620\n",
      "Epoch 10/100, Loss: 0.1478\n",
      "Epoch 11/100, Loss: 0.1337\n",
      "Epoch 12/100, Loss: 0.1217\n",
      "Epoch 13/100, Loss: 0.1078\n",
      "Epoch 14/100, Loss: 0.1014\n",
      "Epoch 15/100, Loss: 0.0901\n",
      "Epoch 16/100, Loss: 0.0613\n",
      "Epoch 17/100, Loss: 0.0534\n",
      "Epoch 18/100, Loss: 0.0474\n",
      "Epoch 19/100, Loss: 0.0414\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=250, Optimizer=SGD\n",
      "Epoch 1/250, Loss: 1.1564\n",
      "Epoch 2/250, Loss: 0.6844\n",
      "Epoch 3/250, Loss: 0.6184\n",
      "Epoch 4/250, Loss: 0.5737\n",
      "Epoch 5/250, Loss: 0.5384\n",
      "Epoch 6/250, Loss: 0.5088\n",
      "Epoch 7/250, Loss: 0.4861\n",
      "Epoch 8/250, Loss: 0.4649\n",
      "Epoch 9/250, Loss: 0.4505\n",
      "Epoch 10/250, Loss: 0.4356\n",
      "Epoch 11/250, Loss: 0.4244\n",
      "Epoch 12/250, Loss: 0.4111\n",
      "Epoch 13/250, Loss: 0.4034\n",
      "Epoch 14/250, Loss: 0.3951\n",
      "Epoch 15/250, Loss: 0.3867\n",
      "Epoch 16/250, Loss: 0.3776\n",
      "Epoch 17/250, Loss: 0.3723\n",
      "Epoch 18/250, Loss: 0.3661\n",
      "Epoch 19/250, Loss: 0.3593\n",
      "Epoch 20/250, Loss: 0.3542\n",
      "Epoch 21/250, Loss: 0.3492\n",
      "Epoch 22/250, Loss: 0.3445\n",
      "Epoch 23/250, Loss: 0.3389\n",
      "Epoch 24/250, Loss: 0.3343\n",
      "Epoch 25/250, Loss: 0.3292\n",
      "Epoch 26/250, Loss: 0.3253\n",
      "Epoch 27/250, Loss: 0.3213\n",
      "Epoch 28/250, Loss: 0.3204\n",
      "Epoch 29/250, Loss: 0.3142\n",
      "Epoch 30/250, Loss: 0.3099\n",
      "Epoch 31/250, Loss: 0.3070\n",
      "Epoch 32/250, Loss: 0.3034\n",
      "Epoch 33/250, Loss: 0.3011\n",
      "Epoch 34/250, Loss: 0.2991\n",
      "Epoch 35/250, Loss: 0.2961\n",
      "Epoch 36/250, Loss: 0.2922\n",
      "Epoch 37/250, Loss: 0.2890\n",
      "Epoch 38/250, Loss: 0.2865\n",
      "Epoch 39/250, Loss: 0.2837\n",
      "Epoch 40/250, Loss: 0.2808\n",
      "Epoch 41/250, Loss: 0.2785\n",
      "Epoch 42/250, Loss: 0.2762\n",
      "Epoch 43/250, Loss: 0.2748\n",
      "Epoch 44/250, Loss: 0.2715\n",
      "Epoch 45/250, Loss: 0.2688\n",
      "Epoch 46/250, Loss: 0.2672\n",
      "Epoch 47/250, Loss: 0.2641\n",
      "Epoch 48/250, Loss: 0.2623\n",
      "Epoch 49/250, Loss: 0.2597\n",
      "Epoch 50/250, Loss: 0.2575\n",
      "Epoch 51/250, Loss: 0.2560\n",
      "Epoch 52/250, Loss: 0.2547\n",
      "Epoch 53/250, Loss: 0.2523\n",
      "Epoch 54/250, Loss: 0.2505\n",
      "Epoch 55/250, Loss: 0.2487\n",
      "Epoch 56/250, Loss: 0.2470\n",
      "Epoch 57/250, Loss: 0.2443\n",
      "Epoch 58/250, Loss: 0.2436\n",
      "Epoch 59/250, Loss: 0.2413\n",
      "Epoch 60/250, Loss: 0.2393\n",
      "Epoch 61/250, Loss: 0.2383\n",
      "Epoch 62/250, Loss: 0.2366\n",
      "Epoch 63/250, Loss: 0.2343\n",
      "Epoch 64/250, Loss: 0.2323\n",
      "Epoch 65/250, Loss: 0.2305\n",
      "Epoch 66/250, Loss: 0.2296\n",
      "Epoch 67/250, Loss: 0.2296\n",
      "Epoch 68/250, Loss: 0.2270\n",
      "Epoch 69/250, Loss: 0.2245\n",
      "Epoch 70/250, Loss: 0.2238\n",
      "Epoch 71/250, Loss: 0.2221\n",
      "Epoch 72/250, Loss: 0.2220\n",
      "Epoch 73/250, Loss: 0.2194\n",
      "Epoch 74/250, Loss: 0.2179\n",
      "Epoch 75/250, Loss: 0.2167\n",
      "Epoch 76/250, Loss: 0.2156\n",
      "Epoch 77/250, Loss: 0.2133\n",
      "Epoch 78/250, Loss: 0.2125\n",
      "Epoch 79/250, Loss: 0.2118\n",
      "Epoch 80/250, Loss: 0.2093\n",
      "Epoch 81/250, Loss: 0.2088\n",
      "Epoch 82/250, Loss: 0.2068\n",
      "Epoch 83/250, Loss: 0.2056\n",
      "Epoch 84/250, Loss: 0.2055\n",
      "Epoch 85/250, Loss: 0.2041\n",
      "Epoch 86/250, Loss: 0.2021\n",
      "Epoch 87/250, Loss: 0.2004\n",
      "Epoch 88/250, Loss: 0.1992\n",
      "Epoch 89/250, Loss: 0.1984\n",
      "Epoch 90/250, Loss: 0.1979\n",
      "Epoch 91/250, Loss: 0.1971\n",
      "Epoch 92/250, Loss: 0.1944\n",
      "Epoch 93/250, Loss: 0.1843\n",
      "Epoch 94/250, Loss: 0.1838\n",
      "Epoch 95/250, Loss: 0.1822\n",
      "Epoch 96/250, Loss: 0.1818\n",
      "Epoch 97/250, Loss: 0.1811\n",
      "Epoch 98/250, Loss: 0.1809\n",
      "Epoch 99/250, Loss: 0.1794\n",
      "Epoch 100/250, Loss: 0.1751\n",
      "Epoch 101/250, Loss: 0.1744\n",
      "Epoch 102/250, Loss: 0.1743\n",
      "Epoch 103/250, Loss: 0.1737\n",
      "Epoch 104/250, Loss: 0.1733\n",
      "Epoch 105/250, Loss: 0.1727\n",
      "Epoch 106/250, Loss: 0.1705\n",
      "Epoch 107/250, Loss: 0.1701\n",
      "Epoch 108/250, Loss: 0.1700\n",
      "Epoch 109/250, Loss: 0.1699\n",
      "Epoch 110/250, Loss: 0.1694\n",
      "Epoch 111/250, Loss: 0.1694\n",
      "Epoch 112/250, Loss: 0.1683\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=250, Optimizer=RMSProp\n",
      "Epoch 1/250, Loss: 0.5414\n",
      "Epoch 2/250, Loss: 0.3400\n",
      "Epoch 3/250, Loss: 0.2864\n",
      "Epoch 4/250, Loss: 0.2543\n",
      "Epoch 5/250, Loss: 0.2297\n",
      "Epoch 6/250, Loss: 0.2088\n",
      "Epoch 7/250, Loss: 0.1924\n",
      "Epoch 8/250, Loss: 0.1766\n",
      "Epoch 9/250, Loss: 0.1631\n",
      "Epoch 10/250, Loss: 0.1512\n",
      "Epoch 11/250, Loss: 0.1400\n",
      "Epoch 12/250, Loss: 0.1296\n",
      "Epoch 13/250, Loss: 0.1192\n",
      "Epoch 14/250, Loss: 0.1096\n",
      "Epoch 15/250, Loss: 0.1011\n",
      "Epoch 16/250, Loss: 0.0934\n",
      "Epoch 17/250, Loss: 0.0851\n",
      "Epoch 18/250, Loss: 0.0766\n",
      "Epoch 19/250, Loss: 0.0541\n",
      "Epoch 20/250, Loss: 0.0477\n",
      "Epoch 21/250, Loss: 0.0432\n",
      "Epoch 22/250, Loss: 0.0387\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=250, Optimizer=Adam\n",
      "Epoch 1/250, Loss: 0.5207\n",
      "Epoch 2/250, Loss: 0.3234\n",
      "Epoch 3/250, Loss: 0.2732\n",
      "Epoch 4/250, Loss: 0.2453\n",
      "Epoch 5/250, Loss: 0.2236\n",
      "Epoch 6/250, Loss: 0.2035\n",
      "Epoch 7/250, Loss: 0.1904\n",
      "Epoch 8/250, Loss: 0.1731\n",
      "Epoch 9/250, Loss: 0.1620\n",
      "Epoch 10/250, Loss: 0.1485\n",
      "Epoch 11/250, Loss: 0.1360\n",
      "Epoch 12/250, Loss: 0.1243\n",
      "Epoch 13/250, Loss: 0.1102\n",
      "Epoch 14/250, Loss: 0.1034\n",
      "Epoch 15/250, Loss: 0.0915\n",
      "Epoch 16/250, Loss: 0.0636\n",
      "Epoch 17/250, Loss: 0.0553\n",
      "Epoch 18/250, Loss: 0.0495\n",
      "Epoch 19/250, Loss: 0.0443\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=350, Optimizer=SGD\n",
      "Epoch 1/350, Loss: 1.2385\n",
      "Epoch 2/350, Loss: 0.6897\n",
      "Epoch 3/350, Loss: 0.6191\n",
      "Epoch 4/350, Loss: 0.5760\n",
      "Epoch 5/350, Loss: 0.5357\n",
      "Epoch 6/350, Loss: 0.5105\n",
      "Epoch 7/350, Loss: 0.4836\n",
      "Epoch 8/350, Loss: 0.4638\n",
      "Epoch 9/350, Loss: 0.4484\n",
      "Epoch 10/350, Loss: 0.4306\n",
      "Epoch 11/350, Loss: 0.4183\n",
      "Epoch 12/350, Loss: 0.4082\n",
      "Epoch 13/350, Loss: 0.3991\n",
      "Epoch 14/350, Loss: 0.3895\n",
      "Epoch 15/350, Loss: 0.3832\n",
      "Epoch 16/350, Loss: 0.3754\n",
      "Epoch 17/350, Loss: 0.3685\n",
      "Epoch 18/350, Loss: 0.3638\n",
      "Epoch 19/350, Loss: 0.3585\n",
      "Epoch 20/350, Loss: 0.3522\n",
      "Epoch 21/350, Loss: 0.3477\n",
      "Epoch 22/350, Loss: 0.3426\n",
      "Epoch 23/350, Loss: 0.3384\n",
      "Epoch 24/350, Loss: 0.3337\n",
      "Epoch 25/350, Loss: 0.3290\n",
      "Epoch 26/350, Loss: 0.3246\n",
      "Epoch 27/350, Loss: 0.3203\n",
      "Epoch 28/350, Loss: 0.3170\n",
      "Epoch 29/350, Loss: 0.3138\n",
      "Epoch 30/350, Loss: 0.3105\n",
      "Epoch 31/350, Loss: 0.3073\n",
      "Epoch 32/350, Loss: 0.3032\n",
      "Epoch 33/350, Loss: 0.3009\n",
      "Epoch 34/350, Loss: 0.2972\n",
      "Epoch 35/350, Loss: 0.2956\n",
      "Epoch 36/350, Loss: 0.2916\n",
      "Epoch 37/350, Loss: 0.2900\n",
      "Epoch 38/350, Loss: 0.2867\n",
      "Epoch 39/350, Loss: 0.2844\n",
      "Epoch 40/350, Loss: 0.2815\n",
      "Epoch 41/350, Loss: 0.2796\n",
      "Epoch 42/350, Loss: 0.2772\n",
      "Epoch 43/350, Loss: 0.2747\n",
      "Epoch 44/350, Loss: 0.2726\n",
      "Epoch 45/350, Loss: 0.2697\n",
      "Epoch 46/350, Loss: 0.2668\n",
      "Epoch 47/350, Loss: 0.2662\n",
      "Epoch 48/350, Loss: 0.2637\n",
      "Epoch 49/350, Loss: 0.2614\n",
      "Epoch 50/350, Loss: 0.2596\n",
      "Epoch 51/350, Loss: 0.2586\n",
      "Epoch 52/350, Loss: 0.2573\n",
      "Epoch 53/350, Loss: 0.2542\n",
      "Epoch 54/350, Loss: 0.2534\n",
      "Epoch 55/350, Loss: 0.2511\n",
      "Epoch 56/350, Loss: 0.2484\n",
      "Epoch 57/350, Loss: 0.2473\n",
      "Epoch 58/350, Loss: 0.2459\n",
      "Epoch 59/350, Loss: 0.2447\n",
      "Epoch 60/350, Loss: 0.2425\n",
      "Epoch 61/350, Loss: 0.2411\n",
      "Epoch 62/350, Loss: 0.2390\n",
      "Epoch 63/350, Loss: 0.2380\n",
      "Epoch 64/350, Loss: 0.2357\n",
      "Epoch 65/350, Loss: 0.2339\n",
      "Epoch 66/350, Loss: 0.2328\n",
      "Epoch 67/350, Loss: 0.2314\n",
      "Epoch 68/350, Loss: 0.2297\n",
      "Epoch 69/350, Loss: 0.2278\n",
      "Epoch 70/350, Loss: 0.2269\n",
      "Epoch 71/350, Loss: 0.2253\n",
      "Epoch 72/350, Loss: 0.2238\n",
      "Epoch 73/350, Loss: 0.2235\n",
      "Epoch 74/350, Loss: 0.2205\n",
      "Epoch 75/350, Loss: 0.2203\n",
      "Epoch 76/350, Loss: 0.2192\n",
      "Epoch 77/350, Loss: 0.2169\n",
      "Epoch 78/350, Loss: 0.2163\n",
      "Epoch 79/350, Loss: 0.2141\n",
      "Epoch 80/350, Loss: 0.2136\n",
      "Epoch 81/350, Loss: 0.2113\n",
      "Epoch 82/350, Loss: 0.2108\n",
      "Epoch 83/350, Loss: 0.2090\n",
      "Epoch 84/350, Loss: 0.2074\n",
      "Epoch 85/350, Loss: 0.2063\n",
      "Epoch 86/350, Loss: 0.2055\n",
      "Epoch 87/350, Loss: 0.2043\n",
      "Epoch 88/350, Loss: 0.2023\n",
      "Epoch 89/350, Loss: 0.2036\n",
      "Epoch 90/350, Loss: 0.2008\n",
      "Epoch 91/350, Loss: 0.1993\n",
      "Epoch 92/350, Loss: 0.1980\n",
      "Epoch 93/350, Loss: 0.1987\n",
      "Epoch 94/350, Loss: 0.1957\n",
      "Epoch 95/350, Loss: 0.1963\n",
      "Epoch 96/350, Loss: 0.1940\n",
      "Epoch 97/350, Loss: 0.1928\n",
      "Epoch 98/350, Loss: 0.1811\n",
      "Epoch 99/350, Loss: 0.1803\n",
      "Epoch 100/350, Loss: 0.1793\n",
      "Epoch 101/350, Loss: 0.1787\n",
      "Epoch 102/350, Loss: 0.1780\n",
      "Epoch 103/350, Loss: 0.1774\n",
      "Epoch 104/350, Loss: 0.1767\n",
      "Epoch 105/350, Loss: 0.1763\n",
      "Epoch 106/350, Loss: 0.1754\n",
      "Epoch 107/350, Loss: 0.1750\n",
      "Epoch 108/350, Loss: 0.1744\n",
      "Epoch 109/350, Loss: 0.1734\n",
      "Epoch 110/350, Loss: 0.1736\n",
      "Epoch 111/350, Loss: 0.1721\n",
      "Epoch 112/350, Loss: 0.1721\n",
      "Epoch 113/350, Loss: 0.1720\n",
      "Epoch 114/350, Loss: 0.1710\n",
      "Epoch 115/350, Loss: 0.1707\n",
      "Epoch 116/350, Loss: 0.1698\n",
      "Epoch 117/350, Loss: 0.1684\n",
      "Epoch 118/350, Loss: 0.1683\n",
      "Epoch 119/350, Loss: 0.1626\n",
      "Epoch 120/350, Loss: 0.1616\n",
      "Epoch 121/350, Loss: 0.1614\n",
      "Epoch 122/350, Loss: 0.1612\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=350, Optimizer=RMSProp\n",
      "Epoch 1/350, Loss: 0.5361\n",
      "Epoch 2/350, Loss: 0.3337\n",
      "Epoch 3/350, Loss: 0.2816\n",
      "Epoch 4/350, Loss: 0.2515\n",
      "Epoch 5/350, Loss: 0.2273\n",
      "Epoch 6/350, Loss: 0.2090\n",
      "Epoch 7/350, Loss: 0.1930\n",
      "Epoch 8/350, Loss: 0.1781\n",
      "Epoch 9/350, Loss: 0.1650\n",
      "Epoch 10/350, Loss: 0.1542\n",
      "Epoch 11/350, Loss: 0.1424\n",
      "Epoch 12/350, Loss: 0.1322\n",
      "Epoch 13/350, Loss: 0.1219\n",
      "Epoch 14/350, Loss: 0.1133\n",
      "Epoch 15/350, Loss: 0.1036\n",
      "Epoch 16/350, Loss: 0.0947\n",
      "Epoch 17/350, Loss: 0.0870\n",
      "Epoch 18/350, Loss: 0.0630\n",
      "Epoch 19/350, Loss: 0.0567\n",
      "Epoch 20/350, Loss: 0.0514\n",
      "Epoch 21/350, Loss: 0.0469\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=5, Pooling=avg, Epochs=350, Optimizer=Adam\n",
      "Epoch 1/350, Loss: 0.5243\n",
      "Epoch 2/350, Loss: 0.3325\n",
      "Epoch 3/350, Loss: 0.2807\n",
      "Epoch 4/350, Loss: 0.2449\n",
      "Epoch 5/350, Loss: 0.2226\n",
      "Epoch 6/350, Loss: 0.2029\n",
      "Epoch 7/350, Loss: 0.1862\n",
      "Epoch 8/350, Loss: 0.1700\n",
      "Epoch 9/350, Loss: 0.1579\n",
      "Epoch 10/350, Loss: 0.1441\n",
      "Epoch 11/350, Loss: 0.1309\n",
      "Epoch 12/350, Loss: 0.1182\n",
      "Epoch 13/350, Loss: 0.1049\n",
      "Epoch 14/350, Loss: 0.0957\n",
      "Epoch 15/350, Loss: 0.0679\n",
      "Epoch 16/350, Loss: 0.0599\n",
      "Epoch 17/350, Loss: 0.0524\n",
      "Epoch 18/350, Loss: 0.0472\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=5, Optimizer=SGD\n",
      "Epoch 1/5, Loss: 1.0814\n",
      "Epoch 2/5, Loss: 0.6333\n",
      "Epoch 3/5, Loss: 0.5458\n",
      "Epoch 4/5, Loss: 0.4897\n",
      "Epoch 5/5, Loss: 0.4482\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=5, Optimizer=RMSProp\n",
      "Epoch 1/5, Loss: 0.6212\n",
      "Epoch 2/5, Loss: 0.3486\n",
      "Epoch 3/5, Loss: 0.2938\n",
      "Epoch 4/5, Loss: 0.2598\n",
      "Epoch 5/5, Loss: 0.2343\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=5, Optimizer=Adam\n",
      "Epoch 1/5, Loss: 0.4787\n",
      "Epoch 2/5, Loss: 0.2971\n",
      "Epoch 3/5, Loss: 0.2495\n",
      "Epoch 4/5, Loss: 0.2170\n",
      "Epoch 5/5, Loss: 0.1907\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=50, Optimizer=SGD\n",
      "Epoch 1/50, Loss: 1.1095\n",
      "Epoch 2/50, Loss: 0.6262\n",
      "Epoch 3/50, Loss: 0.5459\n",
      "Epoch 4/50, Loss: 0.4894\n",
      "Epoch 5/50, Loss: 0.4516\n",
      "Epoch 6/50, Loss: 0.4203\n",
      "Epoch 7/50, Loss: 0.3988\n",
      "Epoch 8/50, Loss: 0.3796\n",
      "Epoch 9/50, Loss: 0.3659\n",
      "Epoch 10/50, Loss: 0.3532\n",
      "Epoch 11/50, Loss: 0.3415\n",
      "Epoch 12/50, Loss: 0.3327\n",
      "Epoch 13/50, Loss: 0.3228\n",
      "Epoch 14/50, Loss: 0.3148\n",
      "Epoch 15/50, Loss: 0.3074\n",
      "Epoch 16/50, Loss: 0.3007\n",
      "Epoch 17/50, Loss: 0.2942\n",
      "Epoch 18/50, Loss: 0.2873\n",
      "Epoch 19/50, Loss: 0.2828\n",
      "Epoch 20/50, Loss: 0.2759\n",
      "Epoch 21/50, Loss: 0.2714\n",
      "Epoch 22/50, Loss: 0.2655\n",
      "Epoch 23/50, Loss: 0.2628\n",
      "Epoch 24/50, Loss: 0.2574\n",
      "Epoch 25/50, Loss: 0.2532\n",
      "Epoch 26/50, Loss: 0.2479\n",
      "Epoch 27/50, Loss: 0.2455\n",
      "Epoch 28/50, Loss: 0.2418\n",
      "Epoch 29/50, Loss: 0.2388\n",
      "Epoch 30/50, Loss: 0.2344\n",
      "Epoch 31/50, Loss: 0.2311\n",
      "Epoch 32/50, Loss: 0.2282\n",
      "Epoch 33/50, Loss: 0.2254\n",
      "Epoch 34/50, Loss: 0.2222\n",
      "Epoch 35/50, Loss: 0.2182\n",
      "Epoch 36/50, Loss: 0.2161\n",
      "Epoch 37/50, Loss: 0.2129\n",
      "Epoch 38/50, Loss: 0.2095\n",
      "Epoch 39/50, Loss: 0.2072\n",
      "Epoch 40/50, Loss: 0.2037\n",
      "Epoch 41/50, Loss: 0.2012\n",
      "Epoch 42/50, Loss: 0.1986\n",
      "Epoch 43/50, Loss: 0.1968\n",
      "Epoch 44/50, Loss: 0.1935\n",
      "Epoch 45/50, Loss: 0.1902\n",
      "Epoch 46/50, Loss: 0.1888\n",
      "Epoch 47/50, Loss: 0.1858\n",
      "Epoch 48/50, Loss: 0.1831\n",
      "Epoch 49/50, Loss: 0.1803\n",
      "Epoch 50/50, Loss: 0.1779\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=50, Optimizer=RMSProp\n",
      "Epoch 1/50, Loss: 0.5672\n",
      "Epoch 2/50, Loss: 0.3287\n",
      "Epoch 3/50, Loss: 0.2809\n",
      "Epoch 4/50, Loss: 0.2478\n",
      "Epoch 5/50, Loss: 0.2226\n",
      "Epoch 6/50, Loss: 0.2028\n",
      "Epoch 7/50, Loss: 0.1849\n",
      "Epoch 8/50, Loss: 0.1703\n",
      "Epoch 9/50, Loss: 0.1548\n",
      "Epoch 10/50, Loss: 0.1422\n",
      "Epoch 11/50, Loss: 0.1291\n",
      "Epoch 12/50, Loss: 0.1186\n",
      "Epoch 13/50, Loss: 0.0852\n",
      "Epoch 14/50, Loss: 0.0766\n",
      "Epoch 15/50, Loss: 0.0680\n",
      "Epoch 16/50, Loss: 0.0621\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=50, Optimizer=Adam\n",
      "Epoch 1/50, Loss: 0.4589\n",
      "Epoch 2/50, Loss: 0.2891\n",
      "Epoch 3/50, Loss: 0.2426\n",
      "Epoch 4/50, Loss: 0.2106\n",
      "Epoch 5/50, Loss: 0.1856\n",
      "Epoch 6/50, Loss: 0.1634\n",
      "Epoch 7/50, Loss: 0.1410\n",
      "Epoch 8/50, Loss: 0.1223\n",
      "Epoch 9/50, Loss: 0.1042\n",
      "Epoch 10/50, Loss: 0.0892\n",
      "Epoch 11/50, Loss: 0.0768\n",
      "Epoch 12/50, Loss: 0.0683\n",
      "Epoch 13/50, Loss: 0.0336\n",
      "Epoch 14/50, Loss: 0.0231\n",
      "Epoch 15/50, Loss: 0.0180\n",
      "Epoch 16/50, Loss: 0.0171\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=100, Optimizer=SGD\n",
      "Epoch 1/100, Loss: 1.0924\n",
      "Epoch 2/100, Loss: 0.6150\n",
      "Epoch 3/100, Loss: 0.5335\n",
      "Epoch 4/100, Loss: 0.4775\n",
      "Epoch 5/100, Loss: 0.4388\n",
      "Epoch 6/100, Loss: 0.4121\n",
      "Epoch 7/100, Loss: 0.3918\n",
      "Epoch 8/100, Loss: 0.3734\n",
      "Epoch 9/100, Loss: 0.3614\n",
      "Epoch 10/100, Loss: 0.3493\n",
      "Epoch 11/100, Loss: 0.3384\n",
      "Epoch 12/100, Loss: 0.3283\n",
      "Epoch 13/100, Loss: 0.3204\n",
      "Epoch 14/100, Loss: 0.3132\n",
      "Epoch 15/100, Loss: 0.3045\n",
      "Epoch 16/100, Loss: 0.2987\n",
      "Epoch 17/100, Loss: 0.2917\n",
      "Epoch 18/100, Loss: 0.2855\n",
      "Epoch 19/100, Loss: 0.2820\n",
      "Epoch 20/100, Loss: 0.2752\n",
      "Epoch 21/100, Loss: 0.2689\n",
      "Epoch 22/100, Loss: 0.2650\n",
      "Epoch 23/100, Loss: 0.2601\n",
      "Epoch 24/100, Loss: 0.2565\n",
      "Epoch 25/100, Loss: 0.2522\n",
      "Epoch 26/100, Loss: 0.2487\n",
      "Epoch 27/100, Loss: 0.2450\n",
      "Epoch 28/100, Loss: 0.2414\n",
      "Epoch 29/100, Loss: 0.2367\n",
      "Epoch 30/100, Loss: 0.2338\n",
      "Epoch 31/100, Loss: 0.2296\n",
      "Epoch 32/100, Loss: 0.2261\n",
      "Epoch 33/100, Loss: 0.2225\n",
      "Epoch 34/100, Loss: 0.2200\n",
      "Epoch 35/100, Loss: 0.2151\n",
      "Epoch 36/100, Loss: 0.2137\n",
      "Epoch 37/100, Loss: 0.2108\n",
      "Epoch 38/100, Loss: 0.2082\n",
      "Epoch 39/100, Loss: 0.2034\n",
      "Epoch 40/100, Loss: 0.2018\n",
      "Epoch 41/100, Loss: 0.1984\n",
      "Epoch 42/100, Loss: 0.1976\n",
      "Epoch 43/100, Loss: 0.1926\n",
      "Epoch 44/100, Loss: 0.1808\n",
      "Epoch 45/100, Loss: 0.1788\n",
      "Epoch 46/100, Loss: 0.1773\n",
      "Epoch 47/100, Loss: 0.1761\n",
      "Epoch 48/100, Loss: 0.1746\n",
      "Epoch 49/100, Loss: 0.1725\n",
      "Epoch 50/100, Loss: 0.1710\n",
      "Epoch 51/100, Loss: 0.1652\n",
      "Epoch 52/100, Loss: 0.1642\n",
      "Epoch 53/100, Loss: 0.1637\n",
      "Epoch 54/100, Loss: 0.1627\n",
      "Epoch 55/100, Loss: 0.1618\n",
      "Epoch 56/100, Loss: 0.1612\n",
      "Epoch 57/100, Loss: 0.1603\n",
      "Epoch 58/100, Loss: 0.1594\n",
      "Epoch 59/100, Loss: 0.1565\n",
      "Epoch 60/100, Loss: 0.1561\n",
      "Epoch 61/100, Loss: 0.1555\n",
      "Epoch 62/100, Loss: 0.1553\n",
      "Epoch 63/100, Loss: 0.1548\n",
      "Epoch 64/100, Loss: 0.1543\n",
      "Epoch 65/100, Loss: 0.1540\n",
      "Epoch 66/100, Loss: 0.1534\n",
      "Epoch 67/100, Loss: 0.1530\n",
      "Epoch 68/100, Loss: 0.1525\n",
      "Epoch 69/100, Loss: 0.1524\n",
      "Epoch 70/100, Loss: 0.1516\n",
      "Epoch 71/100, Loss: 0.1512\n",
      "Epoch 72/100, Loss: 0.1509\n",
      "Epoch 73/100, Loss: 0.1505\n",
      "Epoch 74/100, Loss: 0.1502\n",
      "Epoch 75/100, Loss: 0.1496\n",
      "Epoch 76/100, Loss: 0.1491\n",
      "Epoch 77/100, Loss: 0.1490\n",
      "Epoch 78/100, Loss: 0.1484\n",
      "Epoch 79/100, Loss: 0.1479\n",
      "Epoch 80/100, Loss: 0.1476\n",
      "Epoch 81/100, Loss: 0.1471\n",
      "Epoch 82/100, Loss: 0.1468\n",
      "Epoch 83/100, Loss: 0.1452\n",
      "Epoch 84/100, Loss: 0.1451\n",
      "Epoch 85/100, Loss: 0.1448\n",
      "Epoch 86/100, Loss: 0.1446\n",
      "Epoch 87/100, Loss: 0.1444\n",
      "Epoch 88/100, Loss: 0.1441\n",
      "Epoch 89/100, Loss: 0.1439\n",
      "Epoch 90/100, Loss: 0.1438\n",
      "Epoch 91/100, Loss: 0.1435\n",
      "Epoch 92/100, Loss: 0.1434\n",
      "Epoch 93/100, Loss: 0.1425\n",
      "Epoch 94/100, Loss: 0.1424\n",
      "Epoch 95/100, Loss: 0.1423\n",
      "Epoch 96/100, Loss: 0.1421\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=100, Optimizer=RMSProp\n",
      "Epoch 1/100, Loss: 0.6199\n",
      "Epoch 2/100, Loss: 0.3402\n",
      "Epoch 3/100, Loss: 0.2929\n",
      "Epoch 4/100, Loss: 0.2609\n",
      "Epoch 5/100, Loss: 0.2385\n",
      "Epoch 6/100, Loss: 0.2194\n",
      "Epoch 7/100, Loss: 0.2005\n",
      "Epoch 8/100, Loss: 0.1845\n",
      "Epoch 9/100, Loss: 0.1698\n",
      "Epoch 10/100, Loss: 0.1566\n",
      "Epoch 11/100, Loss: 0.1442\n",
      "Epoch 12/100, Loss: 0.1327\n",
      "Epoch 13/100, Loss: 0.1213\n",
      "Epoch 14/100, Loss: 0.1110\n",
      "Epoch 15/100, Loss: 0.0804\n",
      "Epoch 16/100, Loss: 0.0723\n",
      "Epoch 17/100, Loss: 0.0652\n",
      "Epoch 18/100, Loss: 0.0590\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=100, Optimizer=Adam\n",
      "Epoch 1/100, Loss: 0.4572\n",
      "Epoch 2/100, Loss: 0.2907\n",
      "Epoch 3/100, Loss: 0.2448\n",
      "Epoch 4/100, Loss: 0.2128\n",
      "Epoch 5/100, Loss: 0.1860\n",
      "Epoch 6/100, Loss: 0.1603\n",
      "Epoch 7/100, Loss: 0.1415\n",
      "Epoch 8/100, Loss: 0.1230\n",
      "Epoch 9/100, Loss: 0.1031\n",
      "Epoch 10/100, Loss: 0.0891\n",
      "Epoch 11/100, Loss: 0.0775\n",
      "Epoch 12/100, Loss: 0.0657\n",
      "Epoch 13/100, Loss: 0.0335\n",
      "Epoch 14/100, Loss: 0.0233\n",
      "Epoch 15/100, Loss: 0.0198\n",
      "Epoch 16/100, Loss: 0.0162\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=250, Optimizer=SGD\n",
      "Epoch 1/250, Loss: 1.0800\n",
      "Epoch 2/250, Loss: 0.6278\n",
      "Epoch 3/250, Loss: 0.5449\n",
      "Epoch 4/250, Loss: 0.4881\n",
      "Epoch 5/250, Loss: 0.4486\n",
      "Epoch 6/250, Loss: 0.4179\n",
      "Epoch 7/250, Loss: 0.3956\n",
      "Epoch 8/250, Loss: 0.3783\n",
      "Epoch 9/250, Loss: 0.3615\n",
      "Epoch 10/250, Loss: 0.3504\n",
      "Epoch 11/250, Loss: 0.3408\n",
      "Epoch 12/250, Loss: 0.3308\n",
      "Epoch 13/250, Loss: 0.3207\n",
      "Epoch 14/250, Loss: 0.3125\n",
      "Epoch 15/250, Loss: 0.3047\n",
      "Epoch 16/250, Loss: 0.2986\n",
      "Epoch 17/250, Loss: 0.2916\n",
      "Epoch 18/250, Loss: 0.2879\n",
      "Epoch 19/250, Loss: 0.2799\n",
      "Epoch 20/250, Loss: 0.2746\n",
      "Epoch 21/250, Loss: 0.2690\n",
      "Epoch 22/250, Loss: 0.2649\n",
      "Epoch 23/250, Loss: 0.2597\n",
      "Epoch 24/250, Loss: 0.2552\n",
      "Epoch 25/250, Loss: 0.2521\n",
      "Epoch 26/250, Loss: 0.2469\n",
      "Epoch 27/250, Loss: 0.2437\n",
      "Epoch 28/250, Loss: 0.2391\n",
      "Epoch 29/250, Loss: 0.2359\n",
      "Epoch 30/250, Loss: 0.2321\n",
      "Epoch 31/250, Loss: 0.2275\n",
      "Epoch 32/250, Loss: 0.2252\n",
      "Epoch 33/250, Loss: 0.2222\n",
      "Epoch 34/250, Loss: 0.2186\n",
      "Epoch 35/250, Loss: 0.2157\n",
      "Epoch 36/250, Loss: 0.2121\n",
      "Epoch 37/250, Loss: 0.2087\n",
      "Epoch 38/250, Loss: 0.2065\n",
      "Epoch 39/250, Loss: 0.2047\n",
      "Epoch 40/250, Loss: 0.2001\n",
      "Epoch 41/250, Loss: 0.1961\n",
      "Epoch 42/250, Loss: 0.1952\n",
      "Epoch 43/250, Loss: 0.1916\n",
      "Epoch 44/250, Loss: 0.1896\n",
      "Epoch 45/250, Loss: 0.1877\n",
      "Epoch 46/250, Loss: 0.1844\n",
      "Epoch 47/250, Loss: 0.1804\n",
      "Epoch 48/250, Loss: 0.1791\n",
      "Epoch 49/250, Loss: 0.1748\n",
      "Epoch 50/250, Loss: 0.1729\n",
      "Epoch 51/250, Loss: 0.1696\n",
      "Epoch 52/250, Loss: 0.1686\n",
      "Epoch 53/250, Loss: 0.1671\n",
      "Epoch 54/250, Loss: 0.1626\n",
      "Epoch 55/250, Loss: 0.1610\n",
      "Epoch 56/250, Loss: 0.1588\n",
      "Epoch 57/250, Loss: 0.1452\n",
      "Epoch 58/250, Loss: 0.1428\n",
      "Epoch 59/250, Loss: 0.1416\n",
      "Epoch 60/250, Loss: 0.1401\n",
      "Epoch 61/250, Loss: 0.1388\n",
      "Epoch 62/250, Loss: 0.1380\n",
      "Epoch 63/250, Loss: 0.1364\n",
      "Epoch 64/250, Loss: 0.1303\n",
      "Epoch 65/250, Loss: 0.1290\n",
      "Epoch 66/250, Loss: 0.1281\n",
      "Epoch 67/250, Loss: 0.1277\n",
      "Epoch 68/250, Loss: 0.1270\n",
      "Epoch 69/250, Loss: 0.1262\n",
      "Epoch 70/250, Loss: 0.1254\n",
      "Epoch 71/250, Loss: 0.1225\n",
      "Epoch 72/250, Loss: 0.1219\n",
      "Epoch 73/250, Loss: 0.1215\n",
      "Epoch 74/250, Loss: 0.1209\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=250, Optimizer=RMSProp\n",
      "Epoch 1/250, Loss: 0.5389\n",
      "Epoch 2/250, Loss: 0.3215\n",
      "Epoch 3/250, Loss: 0.2725\n",
      "Epoch 4/250, Loss: 0.2384\n",
      "Epoch 5/250, Loss: 0.2139\n",
      "Epoch 6/250, Loss: 0.1937\n",
      "Epoch 7/250, Loss: 0.1737\n",
      "Epoch 8/250, Loss: 0.1584\n",
      "Epoch 9/250, Loss: 0.1425\n",
      "Epoch 10/250, Loss: 0.1292\n",
      "Epoch 11/250, Loss: 0.1154\n",
      "Epoch 12/250, Loss: 0.1036\n",
      "Epoch 13/250, Loss: 0.0939\n",
      "Epoch 14/250, Loss: 0.0617\n",
      "Epoch 15/250, Loss: 0.0534\n",
      "Epoch 16/250, Loss: 0.0458\n",
      "Epoch 17/250, Loss: 0.0405\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=250, Optimizer=Adam\n",
      "Epoch 1/250, Loss: 0.4660\n",
      "Epoch 2/250, Loss: 0.2962\n",
      "Epoch 3/250, Loss: 0.2475\n",
      "Epoch 4/250, Loss: 0.2151\n",
      "Epoch 5/250, Loss: 0.1925\n",
      "Epoch 6/250, Loss: 0.1675\n",
      "Epoch 7/250, Loss: 0.1465\n",
      "Epoch 8/250, Loss: 0.1310\n",
      "Epoch 9/250, Loss: 0.1135\n",
      "Epoch 10/250, Loss: 0.0973\n",
      "Epoch 11/250, Loss: 0.0834\n",
      "Epoch 12/250, Loss: 0.0718\n",
      "Epoch 13/250, Loss: 0.0631\n",
      "Epoch 14/250, Loss: 0.0325\n",
      "Epoch 15/250, Loss: 0.0227\n",
      "Epoch 16/250, Loss: 0.0174\n",
      "Epoch 17/250, Loss: 0.0160\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=350, Optimizer=SGD\n",
      "Epoch 1/350, Loss: 1.1039\n",
      "Epoch 2/350, Loss: 0.6302\n",
      "Epoch 3/350, Loss: 0.5458\n",
      "Epoch 4/350, Loss: 0.4908\n",
      "Epoch 5/350, Loss: 0.4533\n",
      "Epoch 6/350, Loss: 0.4226\n",
      "Epoch 7/350, Loss: 0.4009\n",
      "Epoch 8/350, Loss: 0.3823\n",
      "Epoch 9/350, Loss: 0.3680\n",
      "Epoch 10/350, Loss: 0.3544\n",
      "Epoch 11/350, Loss: 0.3439\n",
      "Epoch 12/350, Loss: 0.3322\n",
      "Epoch 13/350, Loss: 0.3274\n",
      "Epoch 14/350, Loss: 0.3170\n",
      "Epoch 15/350, Loss: 0.3084\n",
      "Epoch 16/350, Loss: 0.3026\n",
      "Epoch 17/350, Loss: 0.2950\n",
      "Epoch 18/350, Loss: 0.2899\n",
      "Epoch 19/350, Loss: 0.2846\n",
      "Epoch 20/350, Loss: 0.2780\n",
      "Epoch 21/350, Loss: 0.2739\n",
      "Epoch 22/350, Loss: 0.2670\n",
      "Epoch 23/350, Loss: 0.2633\n",
      "Epoch 24/350, Loss: 0.2602\n",
      "Epoch 25/350, Loss: 0.2550\n",
      "Epoch 26/350, Loss: 0.2508\n",
      "Epoch 27/350, Loss: 0.2463\n",
      "Epoch 28/350, Loss: 0.2434\n",
      "Epoch 29/350, Loss: 0.2382\n",
      "Epoch 30/350, Loss: 0.2361\n",
      "Epoch 31/350, Loss: 0.2318\n",
      "Epoch 32/350, Loss: 0.2292\n",
      "Epoch 33/350, Loss: 0.2250\n",
      "Epoch 34/350, Loss: 0.2219\n",
      "Epoch 35/350, Loss: 0.2196\n",
      "Epoch 36/350, Loss: 0.2166\n",
      "Epoch 37/350, Loss: 0.2131\n",
      "Epoch 38/350, Loss: 0.2104\n",
      "Epoch 39/350, Loss: 0.1977\n",
      "Epoch 40/350, Loss: 0.1953\n",
      "Epoch 41/350, Loss: 0.1939\n",
      "Epoch 42/350, Loss: 0.1925\n",
      "Epoch 43/350, Loss: 0.1908\n",
      "Epoch 44/350, Loss: 0.1892\n",
      "Epoch 45/350, Loss: 0.1880\n",
      "Epoch 46/350, Loss: 0.1863\n",
      "Epoch 47/350, Loss: 0.1848\n",
      "Epoch 48/350, Loss: 0.1829\n",
      "Epoch 49/350, Loss: 0.1814\n",
      "Epoch 50/350, Loss: 0.1802\n",
      "Epoch 51/350, Loss: 0.1788\n",
      "Epoch 52/350, Loss: 0.1773\n",
      "Epoch 53/350, Loss: 0.1753\n",
      "Epoch 54/350, Loss: 0.1740\n",
      "Epoch 55/350, Loss: 0.1731\n",
      "Epoch 56/350, Loss: 0.1706\n",
      "Epoch 57/350, Loss: 0.1690\n",
      "Epoch 58/350, Loss: 0.1689\n",
      "Epoch 59/350, Loss: 0.1668\n",
      "Epoch 60/350, Loss: 0.1657\n",
      "Epoch 61/350, Loss: 0.1638\n",
      "Epoch 62/350, Loss: 0.1630\n",
      "Epoch 63/350, Loss: 0.1611\n",
      "Epoch 64/350, Loss: 0.1603\n",
      "Epoch 65/350, Loss: 0.1591\n",
      "Epoch 66/350, Loss: 0.1572\n",
      "Epoch 67/350, Loss: 0.1557\n",
      "Epoch 68/350, Loss: 0.1544\n",
      "Epoch 69/350, Loss: 0.1469\n",
      "Epoch 70/350, Loss: 0.1455\n",
      "Epoch 71/350, Loss: 0.1453\n",
      "Epoch 72/350, Loss: 0.1443\n",
      "Epoch 73/350, Loss: 0.1433\n",
      "Epoch 74/350, Loss: 0.1426\n",
      "Epoch 75/350, Loss: 0.1418\n",
      "Epoch 76/350, Loss: 0.1406\n",
      "Epoch 77/350, Loss: 0.1402\n",
      "Epoch 78/350, Loss: 0.1397\n",
      "Epoch 79/350, Loss: 0.1389\n",
      "Epoch 80/350, Loss: 0.1383\n",
      "Epoch 81/350, Loss: 0.1346\n",
      "Epoch 82/350, Loss: 0.1339\n",
      "Epoch 83/350, Loss: 0.1335\n",
      "Epoch 84/350, Loss: 0.1333\n",
      "Epoch 85/350, Loss: 0.1327\n",
      "Epoch 86/350, Loss: 0.1322\n",
      "Epoch 87/350, Loss: 0.1317\n",
      "Epoch 88/350, Loss: 0.1314\n",
      "Epoch 89/350, Loss: 0.1313\n",
      "Epoch 90/350, Loss: 0.1307\n",
      "Epoch 91/350, Loss: 0.1290\n",
      "Epoch 92/350, Loss: 0.1286\n",
      "Epoch 93/350, Loss: 0.1284\n",
      "Epoch 94/350, Loss: 0.1283\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=350, Optimizer=RMSProp\n",
      "Epoch 1/350, Loss: 0.5580\n",
      "Epoch 2/350, Loss: 0.3337\n",
      "Epoch 3/350, Loss: 0.2823\n",
      "Epoch 4/350, Loss: 0.2518\n",
      "Epoch 5/350, Loss: 0.2250\n",
      "Epoch 6/350, Loss: 0.2057\n",
      "Epoch 7/350, Loss: 0.1874\n",
      "Epoch 8/350, Loss: 0.1705\n",
      "Epoch 9/350, Loss: 0.1556\n",
      "Epoch 10/350, Loss: 0.1418\n",
      "Epoch 11/350, Loss: 0.1288\n",
      "Epoch 12/350, Loss: 0.1178\n",
      "Epoch 13/350, Loss: 0.1063\n",
      "Epoch 14/350, Loss: 0.0969\n",
      "Epoch 15/350, Loss: 0.0657\n",
      "Epoch 16/350, Loss: 0.0581\n",
      "Epoch 17/350, Loss: 0.0507\n",
      "Epoch 18/350, Loss: 0.0455\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=max, Epochs=350, Optimizer=Adam\n",
      "Epoch 1/350, Loss: 0.4642\n",
      "Epoch 2/350, Loss: 0.2908\n",
      "Epoch 3/350, Loss: 0.2451\n",
      "Epoch 4/350, Loss: 0.2111\n",
      "Epoch 5/350, Loss: 0.1870\n",
      "Epoch 6/350, Loss: 0.1636\n",
      "Epoch 7/350, Loss: 0.1423\n",
      "Epoch 8/350, Loss: 0.1227\n",
      "Epoch 9/350, Loss: 0.1062\n",
      "Epoch 10/350, Loss: 0.0920\n",
      "Epoch 11/350, Loss: 0.0804\n",
      "Epoch 12/350, Loss: 0.0675\n",
      "Epoch 13/350, Loss: 0.0610\n",
      "Epoch 14/350, Loss: 0.0276\n",
      "Epoch 15/350, Loss: 0.0195\n",
      "Epoch 16/350, Loss: 0.0159\n",
      "Epoch 17/350, Loss: 0.0135\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=5, Optimizer=SGD\n",
      "Epoch 1/5, Loss: 1.1852\n",
      "Epoch 2/5, Loss: 0.6926\n",
      "Epoch 3/5, Loss: 0.6185\n",
      "Epoch 4/5, Loss: 0.5705\n",
      "Epoch 5/5, Loss: 0.5331\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=5, Optimizer=RMSProp\n",
      "Epoch 1/5, Loss: 0.6723\n",
      "Epoch 2/5, Loss: 0.3708\n",
      "Epoch 3/5, Loss: 0.3079\n",
      "Epoch 4/5, Loss: 0.2727\n",
      "Epoch 5/5, Loss: 0.2443\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=5, Optimizer=Adam\n",
      "Epoch 1/5, Loss: 0.5198\n",
      "Epoch 2/5, Loss: 0.3361\n",
      "Epoch 3/5, Loss: 0.2887\n",
      "Epoch 4/5, Loss: 0.2590\n",
      "Epoch 5/5, Loss: 0.2343\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=50, Optimizer=SGD\n",
      "Epoch 1/50, Loss: 1.2583\n",
      "Epoch 2/50, Loss: 0.6875\n",
      "Epoch 3/50, Loss: 0.6144\n",
      "Epoch 4/50, Loss: 0.5664\n",
      "Epoch 5/50, Loss: 0.5298\n",
      "Epoch 6/50, Loss: 0.4995\n",
      "Epoch 7/50, Loss: 0.4755\n",
      "Epoch 8/50, Loss: 0.4557\n",
      "Epoch 9/50, Loss: 0.4403\n",
      "Epoch 10/50, Loss: 0.4259\n",
      "Epoch 11/50, Loss: 0.4135\n",
      "Epoch 12/50, Loss: 0.4057\n",
      "Epoch 13/50, Loss: 0.3961\n",
      "Epoch 14/50, Loss: 0.3869\n",
      "Epoch 15/50, Loss: 0.3801\n",
      "Epoch 16/50, Loss: 0.3723\n",
      "Epoch 17/50, Loss: 0.3668\n",
      "Epoch 18/50, Loss: 0.3610\n",
      "Epoch 19/50, Loss: 0.3545\n",
      "Epoch 20/50, Loss: 0.3480\n",
      "Epoch 21/50, Loss: 0.3448\n",
      "Epoch 22/50, Loss: 0.3391\n",
      "Epoch 23/50, Loss: 0.3339\n",
      "Epoch 24/50, Loss: 0.3301\n",
      "Epoch 25/50, Loss: 0.3251\n",
      "Epoch 26/50, Loss: 0.3220\n",
      "Epoch 27/50, Loss: 0.3177\n",
      "Epoch 28/50, Loss: 0.3142\n",
      "Epoch 29/50, Loss: 0.3109\n",
      "Epoch 30/50, Loss: 0.3074\n",
      "Epoch 31/50, Loss: 0.3035\n",
      "Epoch 32/50, Loss: 0.3002\n",
      "Epoch 33/50, Loss: 0.2983\n",
      "Epoch 34/50, Loss: 0.2945\n",
      "Epoch 35/50, Loss: 0.2922\n",
      "Epoch 36/50, Loss: 0.2897\n",
      "Epoch 37/50, Loss: 0.2874\n",
      "Epoch 38/50, Loss: 0.2845\n",
      "Epoch 39/50, Loss: 0.2818\n",
      "Epoch 40/50, Loss: 0.2790\n",
      "Epoch 41/50, Loss: 0.2774\n",
      "Epoch 42/50, Loss: 0.2749\n",
      "Epoch 43/50, Loss: 0.2717\n",
      "Epoch 44/50, Loss: 0.2700\n",
      "Epoch 45/50, Loss: 0.2674\n",
      "Epoch 46/50, Loss: 0.2651\n",
      "Epoch 47/50, Loss: 0.2544\n",
      "Epoch 48/50, Loss: 0.2530\n",
      "Epoch 49/50, Loss: 0.2524\n",
      "Epoch 50/50, Loss: 0.2506\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=50, Optimizer=RMSProp\n",
      "Epoch 1/50, Loss: 0.6183\n",
      "Epoch 2/50, Loss: 0.3644\n",
      "Epoch 3/50, Loss: 0.3113\n",
      "Epoch 4/50, Loss: 0.2756\n",
      "Epoch 5/50, Loss: 0.2483\n",
      "Epoch 6/50, Loss: 0.2271\n",
      "Epoch 7/50, Loss: 0.2105\n",
      "Epoch 8/50, Loss: 0.1958\n",
      "Epoch 9/50, Loss: 0.1808\n",
      "Epoch 10/50, Loss: 0.1671\n",
      "Epoch 11/50, Loss: 0.1566\n",
      "Epoch 12/50, Loss: 0.1439\n",
      "Epoch 13/50, Loss: 0.1332\n",
      "Epoch 14/50, Loss: 0.1243\n",
      "Epoch 15/50, Loss: 0.1132\n",
      "Epoch 16/50, Loss: 0.1044\n",
      "Epoch 17/50, Loss: 0.0958\n",
      "Epoch 18/50, Loss: 0.0681\n",
      "Epoch 19/50, Loss: 0.0609\n",
      "Epoch 20/50, Loss: 0.0555\n",
      "Epoch 21/50, Loss: 0.0504\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=50, Optimizer=Adam\n",
      "Epoch 1/50, Loss: 0.5360\n",
      "Epoch 2/50, Loss: 0.3414\n",
      "Epoch 3/50, Loss: 0.2947\n",
      "Epoch 4/50, Loss: 0.2596\n",
      "Epoch 5/50, Loss: 0.2367\n",
      "Epoch 6/50, Loss: 0.2154\n",
      "Epoch 7/50, Loss: 0.1985\n",
      "Epoch 8/50, Loss: 0.1788\n",
      "Epoch 9/50, Loss: 0.1685\n",
      "Epoch 10/50, Loss: 0.1504\n",
      "Epoch 11/50, Loss: 0.1371\n",
      "Epoch 12/50, Loss: 0.1251\n",
      "Epoch 13/50, Loss: 0.1139\n",
      "Epoch 14/50, Loss: 0.1022\n",
      "Epoch 15/50, Loss: 0.0946\n",
      "Epoch 16/50, Loss: 0.0617\n",
      "Epoch 17/50, Loss: 0.0531\n",
      "Epoch 18/50, Loss: 0.0468\n",
      "Epoch 19/50, Loss: 0.0430\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=100, Optimizer=SGD\n",
      "Epoch 1/100, Loss: 1.2322\n",
      "Epoch 2/100, Loss: 0.6996\n",
      "Epoch 3/100, Loss: 0.6199\n",
      "Epoch 4/100, Loss: 0.5692\n",
      "Epoch 5/100, Loss: 0.5282\n",
      "Epoch 6/100, Loss: 0.4962\n",
      "Epoch 7/100, Loss: 0.4684\n",
      "Epoch 8/100, Loss: 0.4471\n",
      "Epoch 9/100, Loss: 0.4299\n",
      "Epoch 10/100, Loss: 0.4166\n",
      "Epoch 11/100, Loss: 0.4050\n",
      "Epoch 12/100, Loss: 0.3955\n",
      "Epoch 13/100, Loss: 0.3842\n",
      "Epoch 14/100, Loss: 0.3765\n",
      "Epoch 15/100, Loss: 0.3711\n",
      "Epoch 16/100, Loss: 0.3619\n",
      "Epoch 17/100, Loss: 0.3556\n",
      "Epoch 18/100, Loss: 0.3486\n",
      "Epoch 19/100, Loss: 0.3452\n",
      "Epoch 20/100, Loss: 0.3390\n",
      "Epoch 21/100, Loss: 0.3337\n",
      "Epoch 22/100, Loss: 0.3300\n",
      "Epoch 23/100, Loss: 0.3246\n",
      "Epoch 24/100, Loss: 0.3204\n",
      "Epoch 25/100, Loss: 0.3174\n",
      "Epoch 26/100, Loss: 0.3129\n",
      "Epoch 27/100, Loss: 0.3090\n",
      "Epoch 28/100, Loss: 0.3052\n",
      "Epoch 29/100, Loss: 0.3020\n",
      "Epoch 30/100, Loss: 0.2988\n",
      "Epoch 31/100, Loss: 0.2945\n",
      "Epoch 32/100, Loss: 0.2919\n",
      "Epoch 33/100, Loss: 0.2887\n",
      "Epoch 34/100, Loss: 0.2875\n",
      "Epoch 35/100, Loss: 0.2837\n",
      "Epoch 36/100, Loss: 0.2805\n",
      "Epoch 37/100, Loss: 0.2782\n",
      "Epoch 38/100, Loss: 0.2754\n",
      "Epoch 39/100, Loss: 0.2727\n",
      "Epoch 40/100, Loss: 0.2704\n",
      "Epoch 41/100, Loss: 0.2679\n",
      "Epoch 42/100, Loss: 0.2664\n",
      "Epoch 43/100, Loss: 0.2633\n",
      "Epoch 44/100, Loss: 0.2609\n",
      "Epoch 45/100, Loss: 0.2585\n",
      "Epoch 46/100, Loss: 0.2572\n",
      "Epoch 47/100, Loss: 0.2548\n",
      "Epoch 48/100, Loss: 0.2532\n",
      "Epoch 49/100, Loss: 0.2497\n",
      "Epoch 50/100, Loss: 0.2487\n",
      "Epoch 51/100, Loss: 0.2458\n",
      "Epoch 52/100, Loss: 0.2451\n",
      "Epoch 53/100, Loss: 0.2437\n",
      "Epoch 54/100, Loss: 0.2326\n",
      "Epoch 55/100, Loss: 0.2312\n",
      "Epoch 56/100, Loss: 0.2299\n",
      "Epoch 57/100, Loss: 0.2291\n",
      "Epoch 58/100, Loss: 0.2285\n",
      "Epoch 59/100, Loss: 0.2271\n",
      "Epoch 60/100, Loss: 0.2257\n",
      "Epoch 61/100, Loss: 0.2251\n",
      "Epoch 62/100, Loss: 0.2237\n",
      "Epoch 63/100, Loss: 0.2241\n",
      "Epoch 64/100, Loss: 0.2226\n",
      "Epoch 65/100, Loss: 0.2217\n",
      "Epoch 66/100, Loss: 0.2206\n",
      "Epoch 67/100, Loss: 0.2204\n",
      "Epoch 68/100, Loss: 0.2189\n",
      "Epoch 69/100, Loss: 0.2181\n",
      "Epoch 70/100, Loss: 0.2175\n",
      "Epoch 71/100, Loss: 0.2164\n",
      "Epoch 72/100, Loss: 0.2154\n",
      "Epoch 73/100, Loss: 0.2148\n",
      "Epoch 74/100, Loss: 0.2132\n",
      "Epoch 75/100, Loss: 0.2129\n",
      "Epoch 76/100, Loss: 0.2123\n",
      "Epoch 77/100, Loss: 0.2111\n",
      "Epoch 78/100, Loss: 0.2107\n",
      "Epoch 79/100, Loss: 0.2093\n",
      "Epoch 80/100, Loss: 0.2084\n",
      "Epoch 81/100, Loss: 0.2080\n",
      "Epoch 82/100, Loss: 0.2070\n",
      "Epoch 83/100, Loss: 0.2062\n",
      "Epoch 84/100, Loss: 0.2006\n",
      "Epoch 85/100, Loss: 0.1993\n",
      "Epoch 86/100, Loss: 0.1989\n",
      "Epoch 87/100, Loss: 0.1986\n",
      "Epoch 88/100, Loss: 0.1984\n",
      "Epoch 89/100, Loss: 0.1979\n",
      "Epoch 90/100, Loss: 0.1973\n",
      "Epoch 91/100, Loss: 0.1970\n",
      "Epoch 92/100, Loss: 0.1966\n",
      "Epoch 93/100, Loss: 0.1960\n",
      "Epoch 94/100, Loss: 0.1955\n",
      "Epoch 95/100, Loss: 0.1951\n",
      "Epoch 96/100, Loss: 0.1947\n",
      "Epoch 97/100, Loss: 0.1944\n",
      "Epoch 98/100, Loss: 0.1939\n",
      "Epoch 99/100, Loss: 0.1932\n",
      "Epoch 100/100, Loss: 0.1929\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=100, Optimizer=RMSProp\n",
      "Epoch 1/100, Loss: 0.5654\n",
      "Epoch 2/100, Loss: 0.3480\n",
      "Epoch 3/100, Loss: 0.2956\n",
      "Epoch 4/100, Loss: 0.2625\n",
      "Epoch 5/100, Loss: 0.2388\n",
      "Epoch 6/100, Loss: 0.2178\n",
      "Epoch 7/100, Loss: 0.2006\n",
      "Epoch 8/100, Loss: 0.1845\n",
      "Epoch 9/100, Loss: 0.1724\n",
      "Epoch 10/100, Loss: 0.1575\n",
      "Epoch 11/100, Loss: 0.1442\n",
      "Epoch 12/100, Loss: 0.1336\n",
      "Epoch 13/100, Loss: 0.1216\n",
      "Epoch 14/100, Loss: 0.1113\n",
      "Epoch 15/100, Loss: 0.1027\n",
      "Epoch 16/100, Loss: 0.0922\n",
      "Epoch 17/100, Loss: 0.0652\n",
      "Epoch 18/100, Loss: 0.0572\n",
      "Epoch 19/100, Loss: 0.0518\n",
      "Epoch 20/100, Loss: 0.0475\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=100, Optimizer=Adam\n",
      "Epoch 1/100, Loss: 0.5139\n",
      "Epoch 2/100, Loss: 0.3282\n",
      "Epoch 3/100, Loss: 0.2822\n",
      "Epoch 4/100, Loss: 0.2495\n",
      "Epoch 5/100, Loss: 0.2283\n",
      "Epoch 6/100, Loss: 0.2082\n",
      "Epoch 7/100, Loss: 0.1905\n",
      "Epoch 8/100, Loss: 0.1733\n",
      "Epoch 9/100, Loss: 0.1597\n",
      "Epoch 10/100, Loss: 0.1464\n",
      "Epoch 11/100, Loss: 0.1317\n",
      "Epoch 12/100, Loss: 0.1172\n",
      "Epoch 13/100, Loss: 0.1067\n",
      "Epoch 14/100, Loss: 0.0946\n",
      "Epoch 15/100, Loss: 0.0849\n",
      "Epoch 16/100, Loss: 0.0541\n",
      "Epoch 17/100, Loss: 0.0443\n",
      "Epoch 18/100, Loss: 0.0393\n",
      "Epoch 19/100, Loss: 0.0357\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=250, Optimizer=SGD\n",
      "Epoch 1/250, Loss: 1.3493\n",
      "Epoch 2/250, Loss: 0.7053\n",
      "Epoch 3/250, Loss: 0.6260\n",
      "Epoch 4/250, Loss: 0.5752\n",
      "Epoch 5/250, Loss: 0.5349\n",
      "Epoch 6/250, Loss: 0.5034\n",
      "Epoch 7/250, Loss: 0.4759\n",
      "Epoch 8/250, Loss: 0.4559\n",
      "Epoch 9/250, Loss: 0.4363\n",
      "Epoch 10/250, Loss: 0.4218\n",
      "Epoch 11/250, Loss: 0.4106\n",
      "Epoch 12/250, Loss: 0.4010\n",
      "Epoch 13/250, Loss: 0.3918\n",
      "Epoch 14/250, Loss: 0.3824\n",
      "Epoch 15/250, Loss: 0.3747\n",
      "Epoch 16/250, Loss: 0.3683\n",
      "Epoch 17/250, Loss: 0.3624\n",
      "Epoch 18/250, Loss: 0.3558\n",
      "Epoch 19/250, Loss: 0.3491\n",
      "Epoch 20/250, Loss: 0.3446\n",
      "Epoch 21/250, Loss: 0.3384\n",
      "Epoch 22/250, Loss: 0.3339\n",
      "Epoch 23/250, Loss: 0.3298\n",
      "Epoch 24/250, Loss: 0.3241\n",
      "Epoch 25/250, Loss: 0.3196\n",
      "Epoch 26/250, Loss: 0.3160\n",
      "Epoch 27/250, Loss: 0.3116\n",
      "Epoch 28/250, Loss: 0.3085\n",
      "Epoch 29/250, Loss: 0.3033\n",
      "Epoch 30/250, Loss: 0.3001\n",
      "Epoch 31/250, Loss: 0.2963\n",
      "Epoch 32/250, Loss: 0.2925\n",
      "Epoch 33/250, Loss: 0.2899\n",
      "Epoch 34/250, Loss: 0.2869\n",
      "Epoch 35/250, Loss: 0.2844\n",
      "Epoch 36/250, Loss: 0.2815\n",
      "Epoch 37/250, Loss: 0.2779\n",
      "Epoch 38/250, Loss: 0.2762\n",
      "Epoch 39/250, Loss: 0.2729\n",
      "Epoch 40/250, Loss: 0.2703\n",
      "Epoch 41/250, Loss: 0.2678\n",
      "Epoch 42/250, Loss: 0.2645\n",
      "Epoch 43/250, Loss: 0.2628\n",
      "Epoch 44/250, Loss: 0.2616\n",
      "Epoch 45/250, Loss: 0.2580\n",
      "Epoch 46/250, Loss: 0.2563\n",
      "Epoch 47/250, Loss: 0.2551\n",
      "Epoch 48/250, Loss: 0.2515\n",
      "Epoch 49/250, Loss: 0.2499\n",
      "Epoch 50/250, Loss: 0.2471\n",
      "Epoch 51/250, Loss: 0.2461\n",
      "Epoch 52/250, Loss: 0.2438\n",
      "Epoch 53/250, Loss: 0.2424\n",
      "Epoch 54/250, Loss: 0.2391\n",
      "Epoch 55/250, Loss: 0.2387\n",
      "Epoch 56/250, Loss: 0.2362\n",
      "Epoch 57/250, Loss: 0.2354\n",
      "Epoch 58/250, Loss: 0.2325\n",
      "Epoch 59/250, Loss: 0.2315\n",
      "Epoch 60/250, Loss: 0.2296\n",
      "Epoch 61/250, Loss: 0.2280\n",
      "Epoch 62/250, Loss: 0.2258\n",
      "Epoch 63/250, Loss: 0.2237\n",
      "Epoch 64/250, Loss: 0.2238\n",
      "Epoch 65/250, Loss: 0.2215\n",
      "Epoch 66/250, Loss: 0.2190\n",
      "Epoch 67/250, Loss: 0.2184\n",
      "Epoch 68/250, Loss: 0.2170\n",
      "Epoch 69/250, Loss: 0.2150\n",
      "Epoch 70/250, Loss: 0.2143\n",
      "Epoch 71/250, Loss: 0.2129\n",
      "Epoch 72/250, Loss: 0.2100\n",
      "Epoch 73/250, Loss: 0.2094\n",
      "Epoch 74/250, Loss: 0.2069\n",
      "Epoch 75/250, Loss: 0.2067\n",
      "Epoch 76/250, Loss: 0.2055\n",
      "Epoch 77/250, Loss: 0.2033\n",
      "Epoch 78/250, Loss: 0.2019\n",
      "Epoch 79/250, Loss: 0.1994\n",
      "Epoch 80/250, Loss: 0.1987\n",
      "Epoch 81/250, Loss: 0.1973\n",
      "Epoch 82/250, Loss: 0.1952\n",
      "Epoch 83/250, Loss: 0.1956\n",
      "Epoch 84/250, Loss: 0.1934\n",
      "Epoch 85/250, Loss: 0.1918\n",
      "Epoch 86/250, Loss: 0.1910\n",
      "Epoch 87/250, Loss: 0.1904\n",
      "Epoch 88/250, Loss: 0.1881\n",
      "Epoch 89/250, Loss: 0.1874\n",
      "Epoch 90/250, Loss: 0.1861\n",
      "Epoch 91/250, Loss: 0.1840\n",
      "Epoch 92/250, Loss: 0.1829\n",
      "Epoch 93/250, Loss: 0.1807\n",
      "Epoch 94/250, Loss: 0.1792\n",
      "Epoch 95/250, Loss: 0.1798\n",
      "Epoch 96/250, Loss: 0.1769\n",
      "Epoch 97/250, Loss: 0.1763\n",
      "Epoch 98/250, Loss: 0.1739\n",
      "Epoch 99/250, Loss: 0.1736\n",
      "Epoch 100/250, Loss: 0.1729\n",
      "Epoch 101/250, Loss: 0.1720\n",
      "Epoch 102/250, Loss: 0.1708\n",
      "Epoch 103/250, Loss: 0.1586\n",
      "Epoch 104/250, Loss: 0.1572\n",
      "Epoch 105/250, Loss: 0.1563\n",
      "Epoch 106/250, Loss: 0.1560\n",
      "Epoch 107/250, Loss: 0.1549\n",
      "Epoch 108/250, Loss: 0.1547\n",
      "Epoch 109/250, Loss: 0.1536\n",
      "Epoch 110/250, Loss: 0.1485\n",
      "Epoch 111/250, Loss: 0.1479\n",
      "Epoch 112/250, Loss: 0.1474\n",
      "Epoch 113/250, Loss: 0.1467\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=250, Optimizer=RMSProp\n",
      "Epoch 1/250, Loss: 0.5830\n",
      "Epoch 2/250, Loss: 0.3564\n",
      "Epoch 3/250, Loss: 0.3027\n",
      "Epoch 4/250, Loss: 0.2646\n",
      "Epoch 5/250, Loss: 0.2390\n",
      "Epoch 6/250, Loss: 0.2190\n",
      "Epoch 7/250, Loss: 0.1993\n",
      "Epoch 8/250, Loss: 0.1842\n",
      "Epoch 9/250, Loss: 0.1697\n",
      "Epoch 10/250, Loss: 0.1555\n",
      "Epoch 11/250, Loss: 0.1435\n",
      "Epoch 12/250, Loss: 0.1318\n",
      "Epoch 13/250, Loss: 0.1201\n",
      "Epoch 14/250, Loss: 0.1103\n",
      "Epoch 15/250, Loss: 0.1008\n",
      "Epoch 16/250, Loss: 0.0909\n",
      "Epoch 17/250, Loss: 0.0825\n",
      "Epoch 18/250, Loss: 0.0566\n",
      "Epoch 19/250, Loss: 0.0486\n",
      "Epoch 20/250, Loss: 0.0439\n",
      "Epoch 21/250, Loss: 0.0396\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=250, Optimizer=Adam\n",
      "Epoch 1/250, Loss: 0.5098\n",
      "Epoch 2/250, Loss: 0.3275\n",
      "Epoch 3/250, Loss: 0.2809\n",
      "Epoch 4/250, Loss: 0.2490\n",
      "Epoch 5/250, Loss: 0.2263\n",
      "Epoch 6/250, Loss: 0.2064\n",
      "Epoch 7/250, Loss: 0.1894\n",
      "Epoch 8/250, Loss: 0.1709\n",
      "Epoch 9/250, Loss: 0.1579\n",
      "Epoch 10/250, Loss: 0.1414\n",
      "Epoch 11/250, Loss: 0.1268\n",
      "Epoch 12/250, Loss: 0.1141\n",
      "Epoch 13/250, Loss: 0.1041\n",
      "Epoch 14/250, Loss: 0.0928\n",
      "Epoch 15/250, Loss: 0.0801\n",
      "Epoch 16/250, Loss: 0.0733\n",
      "Epoch 17/250, Loss: 0.0432\n",
      "Epoch 18/250, Loss: 0.0362\n",
      "Epoch 19/250, Loss: 0.0314\n",
      "Epoch 20/250, Loss: 0.0279\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=350, Optimizer=SGD\n",
      "Epoch 1/350, Loss: 1.1790\n",
      "Epoch 2/350, Loss: 0.6951\n",
      "Epoch 3/350, Loss: 0.6141\n",
      "Epoch 4/350, Loss: 0.5654\n",
      "Epoch 5/350, Loss: 0.5271\n",
      "Epoch 6/350, Loss: 0.4968\n",
      "Epoch 7/350, Loss: 0.4685\n",
      "Epoch 8/350, Loss: 0.4479\n",
      "Epoch 9/350, Loss: 0.4320\n",
      "Epoch 10/350, Loss: 0.4162\n",
      "Epoch 11/350, Loss: 0.4045\n",
      "Epoch 12/350, Loss: 0.3940\n",
      "Epoch 13/350, Loss: 0.3851\n",
      "Epoch 14/350, Loss: 0.3766\n",
      "Epoch 15/350, Loss: 0.3677\n",
      "Epoch 16/350, Loss: 0.3627\n",
      "Epoch 17/350, Loss: 0.3561\n",
      "Epoch 18/350, Loss: 0.3493\n",
      "Epoch 19/350, Loss: 0.3438\n",
      "Epoch 20/350, Loss: 0.3381\n",
      "Epoch 21/350, Loss: 0.3323\n",
      "Epoch 22/350, Loss: 0.3275\n",
      "Epoch 23/350, Loss: 0.3236\n",
      "Epoch 24/350, Loss: 0.3198\n",
      "Epoch 25/350, Loss: 0.3153\n",
      "Epoch 26/350, Loss: 0.3123\n",
      "Epoch 27/350, Loss: 0.3075\n",
      "Epoch 28/350, Loss: 0.3041\n",
      "Epoch 29/350, Loss: 0.3008\n",
      "Epoch 30/350, Loss: 0.2980\n",
      "Epoch 31/350, Loss: 0.2943\n",
      "Epoch 32/350, Loss: 0.2912\n",
      "Epoch 33/350, Loss: 0.2873\n",
      "Epoch 34/350, Loss: 0.2851\n",
      "Epoch 35/350, Loss: 0.2823\n",
      "Epoch 36/350, Loss: 0.2799\n",
      "Epoch 37/350, Loss: 0.2771\n",
      "Epoch 38/350, Loss: 0.2739\n",
      "Epoch 39/350, Loss: 0.2718\n",
      "Epoch 40/350, Loss: 0.2700\n",
      "Epoch 41/350, Loss: 0.2677\n",
      "Epoch 42/350, Loss: 0.2643\n",
      "Epoch 43/350, Loss: 0.2635\n",
      "Epoch 44/350, Loss: 0.2599\n",
      "Epoch 45/350, Loss: 0.2584\n",
      "Epoch 46/350, Loss: 0.2563\n",
      "Epoch 47/350, Loss: 0.2542\n",
      "Epoch 48/350, Loss: 0.2518\n",
      "Epoch 49/350, Loss: 0.2503\n",
      "Epoch 50/350, Loss: 0.2476\n",
      "Epoch 51/350, Loss: 0.2456\n",
      "Epoch 52/350, Loss: 0.2436\n",
      "Epoch 53/350, Loss: 0.2420\n",
      "Epoch 54/350, Loss: 0.2395\n",
      "Epoch 55/350, Loss: 0.2383\n",
      "Epoch 56/350, Loss: 0.2363\n",
      "Epoch 57/350, Loss: 0.2341\n",
      "Epoch 58/350, Loss: 0.2326\n",
      "Epoch 59/350, Loss: 0.2314\n",
      "Epoch 60/350, Loss: 0.2301\n",
      "Epoch 61/350, Loss: 0.2284\n",
      "Epoch 62/350, Loss: 0.2260\n",
      "Epoch 63/350, Loss: 0.2242\n",
      "Epoch 64/350, Loss: 0.2229\n",
      "Epoch 65/350, Loss: 0.2210\n",
      "Epoch 66/350, Loss: 0.2206\n",
      "Epoch 67/350, Loss: 0.2181\n",
      "Epoch 68/350, Loss: 0.2165\n",
      "Epoch 69/350, Loss: 0.2148\n",
      "Epoch 70/350, Loss: 0.2134\n",
      "Epoch 71/350, Loss: 0.2113\n",
      "Epoch 72/350, Loss: 0.2094\n",
      "Epoch 73/350, Loss: 0.2001\n",
      "Epoch 74/350, Loss: 0.1986\n",
      "Epoch 75/350, Loss: 0.1975\n",
      "Epoch 76/350, Loss: 0.1965\n",
      "Epoch 77/350, Loss: 0.1956\n",
      "Epoch 78/350, Loss: 0.1950\n",
      "Epoch 79/350, Loss: 0.1948\n",
      "Epoch 80/350, Loss: 0.1932\n",
      "Epoch 81/350, Loss: 0.1927\n",
      "Epoch 82/350, Loss: 0.1917\n",
      "Epoch 83/350, Loss: 0.1866\n",
      "Epoch 84/350, Loss: 0.1859\n",
      "Epoch 85/350, Loss: 0.1854\n",
      "Epoch 86/350, Loss: 0.1852\n",
      "Epoch 87/350, Loss: 0.1845\n",
      "Epoch 88/350, Loss: 0.1841\n",
      "Epoch 89/350, Loss: 0.1838\n",
      "Epoch 90/350, Loss: 0.1831\n",
      "Epoch 91/350, Loss: 0.1826\n",
      "Epoch 92/350, Loss: 0.1801\n",
      "Epoch 93/350, Loss: 0.1795\n",
      "Epoch 94/350, Loss: 0.1795\n",
      "Epoch 95/350, Loss: 0.1791\n",
      "Epoch 96/350, Loss: 0.1789\n",
      "Epoch 97/350, Loss: 0.1786\n",
      "Epoch 98/350, Loss: 0.1783\n",
      "Epoch 99/350, Loss: 0.1780\n",
      "Epoch 100/350, Loss: 0.1779\n",
      "Epoch 101/350, Loss: 0.1779\n",
      "Epoch 102/350, Loss: 0.1762\n",
      "Epoch 103/350, Loss: 0.1762\n",
      "Epoch 104/350, Loss: 0.1759\n",
      "Epoch 105/350, Loss: 0.1758\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=350, Optimizer=RMSProp\n",
      "Epoch 1/350, Loss: 0.5596\n",
      "Epoch 2/350, Loss: 0.3561\n",
      "Epoch 3/350, Loss: 0.3013\n",
      "Epoch 4/350, Loss: 0.2680\n",
      "Epoch 5/350, Loss: 0.2434\n",
      "Epoch 6/350, Loss: 0.2244\n",
      "Epoch 7/350, Loss: 0.2076\n",
      "Epoch 8/350, Loss: 0.1918\n",
      "Epoch 9/350, Loss: 0.1778\n",
      "Epoch 10/350, Loss: 0.1642\n",
      "Epoch 11/350, Loss: 0.1530\n",
      "Epoch 12/350, Loss: 0.1424\n",
      "Epoch 13/350, Loss: 0.1327\n",
      "Epoch 14/350, Loss: 0.1226\n",
      "Epoch 15/350, Loss: 0.0917\n",
      "Epoch 16/350, Loss: 0.0845\n",
      "Epoch 17/350, Loss: 0.0778\n",
      "Epoch 18/350, Loss: 0.0719\n",
      "Early stopping triggered!\n",
      "\n",
      "Running: Kernel Size=7, Pooling=avg, Epochs=350, Optimizer=Adam\n",
      "Epoch 1/350, Loss: 0.5154\n",
      "Epoch 2/350, Loss: 0.3317\n",
      "Epoch 3/350, Loss: 0.2852\n",
      "Epoch 4/350, Loss: 0.2531\n",
      "Epoch 5/350, Loss: 0.2294\n",
      "Epoch 6/350, Loss: 0.2076\n",
      "Epoch 7/350, Loss: 0.1898\n",
      "Epoch 8/350, Loss: 0.1735\n",
      "Epoch 9/350, Loss: 0.1574\n",
      "Epoch 10/350, Loss: 0.1439\n",
      "Epoch 11/350, Loss: 0.1310\n",
      "Epoch 12/350, Loss: 0.1161\n",
      "Epoch 13/350, Loss: 0.1024\n",
      "Epoch 14/350, Loss: 0.0931\n",
      "Epoch 15/350, Loss: 0.0617\n",
      "Epoch 16/350, Loss: 0.0524\n",
      "Epoch 17/350, Loss: 0.0452\n",
      "Epoch 18/350, Loss: 0.0408\n",
      "Early stopping triggered!\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 5, 'optimizer': 'SGD', 'test_loss': 0.43094489317906054, 'accuracy': 84.13}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 5, 'optimizer': 'RMSProp', 'test_loss': 0.24008869700416735, 'accuracy': 91.16}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 5, 'optimizer': 'Adam', 'test_loss': 0.2579388116733937, 'accuracy': 91.04}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 50, 'optimizer': 'SGD', 'test_loss': 0.26458968665403654, 'accuracy': 90.57}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 50, 'optimizer': 'RMSProp', 'test_loss': 0.37874259658252135, 'accuracy': 92.23}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 50, 'optimizer': 'Adam', 'test_loss': 0.3299906305685828, 'accuracy': 92.44}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 100, 'optimizer': 'SGD', 'test_loss': 0.24801679738337482, 'accuracy': 91.53}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 100, 'optimizer': 'RMSProp', 'test_loss': 0.3269731342981133, 'accuracy': 92.23}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 100, 'optimizer': 'Adam', 'test_loss': 0.31076614351212223, 'accuracy': 92.37}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 250, 'optimizer': 'SGD', 'test_loss': 0.23982189397645903, 'accuracy': 91.65}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 250, 'optimizer': 'RMSProp', 'test_loss': 0.3767722918640209, 'accuracy': 91.92}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 250, 'optimizer': 'Adam', 'test_loss': 0.38201457761888263, 'accuracy': 92.35}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 350, 'optimizer': 'SGD', 'test_loss': 0.24538174762001522, 'accuracy': 91.76}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 350, 'optimizer': 'RMSProp', 'test_loss': 0.2926526592124867, 'accuracy': 92.64}\n",
      "{'kernel_size': 3, 'pooling': 'max', 'epochs': 350, 'optimizer': 'Adam', 'test_loss': 0.3465314358472824, 'accuracy': 92.12}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 5, 'optimizer': 'SGD', 'test_loss': 0.55710149113136, 'accuracy': 79.09}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 5, 'optimizer': 'RMSProp', 'test_loss': 0.24861215828340263, 'accuracy': 91.05}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 5, 'optimizer': 'Adam', 'test_loss': 0.2641975209116936, 'accuracy': 90.59}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 50, 'optimizer': 'SGD', 'test_loss': 0.32473396208090116, 'accuracy': 87.83}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 50, 'optimizer': 'RMSProp', 'test_loss': 0.28981416163187995, 'accuracy': 92.53}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 50, 'optimizer': 'Adam', 'test_loss': 0.2740147625909576, 'accuracy': 92.46}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 100, 'optimizer': 'SGD', 'test_loss': 0.29379717741585987, 'accuracy': 89.3}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 100, 'optimizer': 'RMSProp', 'test_loss': 0.2620364902894708, 'accuracy': 92.69}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 100, 'optimizer': 'Adam', 'test_loss': 0.25803872207297557, 'accuracy': 92.76}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 250, 'optimizer': 'SGD', 'test_loss': 0.2726663029457949, 'accuracy': 90.62}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 250, 'optimizer': 'RMSProp', 'test_loss': 0.25022273986965793, 'accuracy': 92.62}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 250, 'optimizer': 'Adam', 'test_loss': 0.277764378091957, 'accuracy': 92.64}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 350, 'optimizer': 'SGD', 'test_loss': 0.26870928553840784, 'accuracy': 90.52}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 350, 'optimizer': 'RMSProp', 'test_loss': 0.2676950588916676, 'accuracy': 92.21}\n",
      "{'kernel_size': 3, 'pooling': 'avg', 'epochs': 350, 'optimizer': 'Adam', 'test_loss': 0.2735259738526767, 'accuracy': 92.74}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 5, 'optimizer': 'SGD', 'test_loss': 0.4680966459497621, 'accuracy': 83.14}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 5, 'optimizer': 'RMSProp', 'test_loss': 0.24940155173027062, 'accuracy': 90.94}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 5, 'optimizer': 'Adam', 'test_loss': 0.24752040820408472, 'accuracy': 90.78}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 50, 'optimizer': 'SGD', 'test_loss': 0.25186752669418916, 'accuracy': 91.07}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 50, 'optimizer': 'RMSProp', 'test_loss': 0.3759718072376674, 'accuracy': 92.05}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 50, 'optimizer': 'Adam', 'test_loss': 0.3303672574177573, 'accuracy': 92.53}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 100, 'optimizer': 'SGD', 'test_loss': 0.24165074338641349, 'accuracy': 91.94}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 100, 'optimizer': 'RMSProp', 'test_loss': 0.36110122011432166, 'accuracy': 91.74}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 100, 'optimizer': 'Adam', 'test_loss': 0.41558344586740564, 'accuracy': 91.91}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 250, 'optimizer': 'SGD', 'test_loss': 0.2422922717619546, 'accuracy': 91.78}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 250, 'optimizer': 'RMSProp', 'test_loss': 0.3272731589931476, 'accuracy': 92.31}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 250, 'optimizer': 'Adam', 'test_loss': 0.3528561079049412, 'accuracy': 92.26}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 350, 'optimizer': 'SGD', 'test_loss': 0.24181282699485368, 'accuracy': 91.64}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 350, 'optimizer': 'RMSProp', 'test_loss': 0.33371789149845704, 'accuracy': 91.82}\n",
      "{'kernel_size': 5, 'pooling': 'max', 'epochs': 350, 'optimizer': 'Adam', 'test_loss': 0.36397807818802097, 'accuracy': 91.74}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 5, 'optimizer': 'SGD', 'test_loss': 0.5286088050166263, 'accuracy': 80.47}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 5, 'optimizer': 'RMSProp', 'test_loss': 0.27276835260511956, 'accuracy': 90.63}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 5, 'optimizer': 'Adam', 'test_loss': 0.2657605628424053, 'accuracy': 90.22}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 50, 'optimizer': 'SGD', 'test_loss': 0.31099424624367605, 'accuracy': 88.81}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 50, 'optimizer': 'RMSProp', 'test_loss': 0.3113269985099382, 'accuracy': 92.12}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 50, 'optimizer': 'Adam', 'test_loss': 0.31223503315137535, 'accuracy': 92.32}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 100, 'optimizer': 'SGD', 'test_loss': 0.2675938863731638, 'accuracy': 90.7}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 100, 'optimizer': 'RMSProp', 'test_loss': 0.29125407413591314, 'accuracy': 92.21}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 100, 'optimizer': 'Adam', 'test_loss': 0.3096168758937075, 'accuracy': 92.31}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 250, 'optimizer': 'SGD', 'test_loss': 0.26197290533705603, 'accuracy': 90.93}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 250, 'optimizer': 'RMSProp', 'test_loss': 0.34518449678073954, 'accuracy': 92.31}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 250, 'optimizer': 'Adam', 'test_loss': 0.28122732429942, 'accuracy': 92.94}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 350, 'optimizer': 'SGD', 'test_loss': 0.26779536789731134, 'accuracy': 90.92}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 350, 'optimizer': 'RMSProp', 'test_loss': 0.3222905991575386, 'accuracy': 92.04}\n",
      "{'kernel_size': 5, 'pooling': 'avg', 'epochs': 350, 'optimizer': 'Adam', 'test_loss': 0.293657213355167, 'accuracy': 92.13}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 5, 'optimizer': 'SGD', 'test_loss': 0.4547117103504229, 'accuracy': 83.36}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 5, 'optimizer': 'RMSProp', 'test_loss': 0.3060779550784751, 'accuracy': 88.56}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 5, 'optimizer': 'Adam', 'test_loss': 0.2571365666351741, 'accuracy': 90.66}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 50, 'optimizer': 'SGD', 'test_loss': 0.26685013159920895, 'accuracy': 90.63}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 50, 'optimizer': 'RMSProp', 'test_loss': 0.32868760880790177, 'accuracy': 90.98}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 50, 'optimizer': 'Adam', 'test_loss': 0.3998615386648269, 'accuracy': 92.1}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 100, 'optimizer': 'SGD', 'test_loss': 0.24843988416692878, 'accuracy': 91.38}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 100, 'optimizer': 'RMSProp', 'test_loss': 0.3402348984080025, 'accuracy': 91.47}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 100, 'optimizer': 'Adam', 'test_loss': 0.39317257381692716, 'accuracy': 92.05}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 250, 'optimizer': 'SGD', 'test_loss': 0.25013690517295767, 'accuracy': 91.32}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 250, 'optimizer': 'RMSProp', 'test_loss': 0.3699364083111021, 'accuracy': 91.61}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 250, 'optimizer': 'Adam', 'test_loss': 0.4445735880067274, 'accuracy': 91.8}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 350, 'optimizer': 'SGD', 'test_loss': 0.25151326092360893, 'accuracy': 91.4}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 350, 'optimizer': 'RMSProp', 'test_loss': 0.37762322738955295, 'accuracy': 91.38}\n",
      "{'kernel_size': 7, 'pooling': 'max', 'epochs': 350, 'optimizer': 'Adam', 'test_loss': 0.4270566691043256, 'accuracy': 91.95}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 5, 'optimizer': 'SGD', 'test_loss': 0.530015652315526, 'accuracy': 80.65}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 5, 'optimizer': 'RMSProp', 'test_loss': 0.2787779565853409, 'accuracy': 90.05}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 5, 'optimizer': 'Adam', 'test_loss': 0.2642956130866763, 'accuracy': 90.39}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 50, 'optimizer': 'SGD', 'test_loss': 0.30607688247780257, 'accuracy': 89.01}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 50, 'optimizer': 'RMSProp', 'test_loss': 0.333672735415682, 'accuracy': 91.79}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 50, 'optimizer': 'Adam', 'test_loss': 0.35333083117310005, 'accuracy': 91.48}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 100, 'optimizer': 'SGD', 'test_loss': 0.27725718990911413, 'accuracy': 90.32}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 100, 'optimizer': 'RMSProp', 'test_loss': 0.35784392077711563, 'accuracy': 91.25}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 100, 'optimizer': 'Adam', 'test_loss': 0.34308574082259136, 'accuracy': 92.06}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 250, 'optimizer': 'SGD', 'test_loss': 0.2656991330883171, 'accuracy': 90.82}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 250, 'optimizer': 'RMSProp', 'test_loss': 0.34203385391944574, 'accuracy': 91.78}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 250, 'optimizer': 'Adam', 'test_loss': 0.36172231819622125, 'accuracy': 92.47}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 350, 'optimizer': 'SGD', 'test_loss': 0.26638962762265267, 'accuracy': 90.62}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 350, 'optimizer': 'RMSProp', 'test_loss': 0.312676953269711, 'accuracy': 91.1}\n",
      "{'kernel_size': 7, 'pooling': 'avg', 'epochs': 350, 'optimizer': 'Adam', 'test_loss': 0.32157170725396916, 'accuracy': 92.12}\n"
     ]
    }
   ],
   "source": [
    "# Experiment Setup\n",
    "kernel_sizes = [3, 5, 7]\n",
    "pooling_types = ['max', 'avg']\n",
    "epochs = [5, 50, 100, 250, 350]\n",
    "optimizers = ['SGD', 'RMSProp', 'Adam']\n",
    "\n",
    "# Results Storage\n",
    "results = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for kernel_size in kernel_sizes:\n",
    "    for pooling_type in pooling_types:\n",
    "        for epoch in epochs:\n",
    "            for optimizer_name in optimizers:\n",
    "                print(f\"\\nRunning: Kernel Size={kernel_size}, Pooling={pooling_type}, Epochs={epoch}, Optimizer={optimizer_name}\")\n",
    "                \n",
    "                model = CNN(kernel_size, pooling_type).to(device)\n",
    "\n",
    "                if optimizer_name == 'SGD':\n",
    "                    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "                elif optimizer_name == 'RMSProp':\n",
    "                    optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "                elif optimizer_name == 'Adam':\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "                scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "\n",
    "                trained_model = train_model(model, optimizer, scheduler, criterion, num_epochs=epoch)\n",
    "\n",
    "                # Evaluate Model\n",
    "                trained_model.eval()\n",
    "                test_loss = 0.0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in test_loader:\n",
    "                        images, labels = images.to(device), labels.to(device)\n",
    "                        outputs = trained_model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        test_loss += loss.item()\n",
    "                        _, predicted = torch.max(outputs, 1)\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "\n",
    "                accuracy = 100 * correct / total\n",
    "                results.append({\n",
    "                    'kernel_size': kernel_size,\n",
    "                    'pooling': pooling_type,\n",
    "                    'epochs': epoch,\n",
    "                    'optimizer': optimizer_name,\n",
    "                    'test_loss': test_loss / len(test_loader),\n",
    "                    'accuracy': accuracy\n",
    "                })\n",
    "\n",
    "# Print Results\n",
    "for result in results:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
